{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "import tensorflow\n",
    "import keras\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rented Bike Count</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Wind speed (m/s)</th>\n",
       "      <th>Visibility (10m)</th>\n",
       "      <th>Dew point temperature(°C)</th>\n",
       "      <th>Solar Radiation (MJ/m2)</th>\n",
       "      <th>Rainfall(mm)</th>\n",
       "      <th>Snowfall (cm)</th>\n",
       "      <th>Seasons</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>Functioning Day</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-12-01</th>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>37</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2000</td>\n",
       "      <td>-17.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-01</th>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2000</td>\n",
       "      <td>-17.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-01</th>\n",
       "      <td>173</td>\n",
       "      <td>2</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>-17.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-01</th>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>-6.2</td>\n",
       "      <td>40</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2000</td>\n",
       "      <td>-17.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-01</th>\n",
       "      <td>78</td>\n",
       "      <td>4</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>36</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2000</td>\n",
       "      <td>-18.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-30</th>\n",
       "      <td>1003</td>\n",
       "      <td>19</td>\n",
       "      <td>4.2</td>\n",
       "      <td>34</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1894</td>\n",
       "      <td>-10.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-30</th>\n",
       "      <td>764</td>\n",
       "      <td>20</td>\n",
       "      <td>3.4</td>\n",
       "      <td>37</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2000</td>\n",
       "      <td>-9.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-30</th>\n",
       "      <td>694</td>\n",
       "      <td>21</td>\n",
       "      <td>2.6</td>\n",
       "      <td>39</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1968</td>\n",
       "      <td>-9.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-30</th>\n",
       "      <td>712</td>\n",
       "      <td>22</td>\n",
       "      <td>2.1</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1859</td>\n",
       "      <td>-9.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-30</th>\n",
       "      <td>584</td>\n",
       "      <td>23</td>\n",
       "      <td>1.9</td>\n",
       "      <td>43</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1909</td>\n",
       "      <td>-9.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8760 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Rented Bike Count  Hour  Temperature(°C)  Humidity(%)  \\\n",
       "Date                                                                \n",
       "2017-12-01                254     0             -5.2           37   \n",
       "2017-12-01                204     1             -5.5           38   \n",
       "2017-12-01                173     2             -6.0           39   \n",
       "2017-12-01                107     3             -6.2           40   \n",
       "2017-12-01                 78     4             -6.0           36   \n",
       "...                       ...   ...              ...          ...   \n",
       "2018-11-30               1003    19              4.2           34   \n",
       "2018-11-30                764    20              3.4           37   \n",
       "2018-11-30                694    21              2.6           39   \n",
       "2018-11-30                712    22              2.1           41   \n",
       "2018-11-30                584    23              1.9           43   \n",
       "\n",
       "            Wind speed (m/s)  Visibility (10m)  Dew point temperature(°C)  \\\n",
       "Date                                                                        \n",
       "2017-12-01               2.2              2000                      -17.6   \n",
       "2017-12-01               0.8              2000                      -17.6   \n",
       "2017-12-01               1.0              2000                      -17.7   \n",
       "2017-12-01               0.9              2000                      -17.6   \n",
       "2017-12-01               2.3              2000                      -18.6   \n",
       "...                      ...               ...                        ...   \n",
       "2018-11-30               2.6              1894                      -10.3   \n",
       "2018-11-30               2.3              2000                       -9.9   \n",
       "2018-11-30               0.3              1968                       -9.9   \n",
       "2018-11-30               1.0              1859                       -9.8   \n",
       "2018-11-30               1.3              1909                       -9.3   \n",
       "\n",
       "            Solar Radiation (MJ/m2)  Rainfall(mm)  Snowfall (cm) Seasons  \\\n",
       "Date                                                                       \n",
       "2017-12-01                      0.0           0.0            0.0  Winter   \n",
       "2017-12-01                      0.0           0.0            0.0  Winter   \n",
       "2017-12-01                      0.0           0.0            0.0  Winter   \n",
       "2017-12-01                      0.0           0.0            0.0  Winter   \n",
       "2017-12-01                      0.0           0.0            0.0  Winter   \n",
       "...                             ...           ...            ...     ...   \n",
       "2018-11-30                      0.0           0.0            0.0  Autumn   \n",
       "2018-11-30                      0.0           0.0            0.0  Autumn   \n",
       "2018-11-30                      0.0           0.0            0.0  Autumn   \n",
       "2018-11-30                      0.0           0.0            0.0  Autumn   \n",
       "2018-11-30                      0.0           0.0            0.0  Autumn   \n",
       "\n",
       "               Holiday Functioning Day  \n",
       "Date                                    \n",
       "2017-12-01  No Holiday             Yes  \n",
       "2017-12-01  No Holiday             Yes  \n",
       "2017-12-01  No Holiday             Yes  \n",
       "2017-12-01  No Holiday             Yes  \n",
       "2017-12-01  No Holiday             Yes  \n",
       "...                ...             ...  \n",
       "2018-11-30  No Holiday             Yes  \n",
       "2018-11-30  No Holiday             Yes  \n",
       "2018-11-30  No Holiday             Yes  \n",
       "2018-11-30  No Holiday             Yes  \n",
       "2018-11-30  No Holiday             Yes  \n",
       "\n",
       "[8760 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('coursework_other.csv', encoding = 'unicode_escape', parse_dates=['Date'], dayfirst=True, index_col=['Date'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rented Bike Count</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Wind speed (m/s)</th>\n",
       "      <th>Visibility (10m)</th>\n",
       "      <th>Dew point temperature(°C)</th>\n",
       "      <th>Solar Radiation (MJ/m2)</th>\n",
       "      <th>Rainfall(mm)</th>\n",
       "      <th>Snowfall (cm)</th>\n",
       "      <th>Seasons</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>Functioning Day</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>DayOfWeek</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-12-01</th>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>37</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2000</td>\n",
       "      <td>-17.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-01</th>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2000</td>\n",
       "      <td>-17.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-01</th>\n",
       "      <td>173</td>\n",
       "      <td>2</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>-17.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-01</th>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>-6.2</td>\n",
       "      <td>40</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2000</td>\n",
       "      <td>-17.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-01</th>\n",
       "      <td>78</td>\n",
       "      <td>4</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>36</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2000</td>\n",
       "      <td>-18.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-30</th>\n",
       "      <td>1003</td>\n",
       "      <td>19</td>\n",
       "      <td>4.2</td>\n",
       "      <td>34</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1894</td>\n",
       "      <td>-10.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-30</th>\n",
       "      <td>764</td>\n",
       "      <td>20</td>\n",
       "      <td>3.4</td>\n",
       "      <td>37</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2000</td>\n",
       "      <td>-9.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-30</th>\n",
       "      <td>694</td>\n",
       "      <td>21</td>\n",
       "      <td>2.6</td>\n",
       "      <td>39</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1968</td>\n",
       "      <td>-9.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-30</th>\n",
       "      <td>712</td>\n",
       "      <td>22</td>\n",
       "      <td>2.1</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1859</td>\n",
       "      <td>-9.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-30</th>\n",
       "      <td>584</td>\n",
       "      <td>23</td>\n",
       "      <td>1.9</td>\n",
       "      <td>43</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1909</td>\n",
       "      <td>-9.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8760 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Rented Bike Count  Hour  Temperature(°C)  Humidity(%)  \\\n",
       "Date                                                                \n",
       "2017-12-01                254     0             -5.2           37   \n",
       "2017-12-01                204     1             -5.5           38   \n",
       "2017-12-01                173     2             -6.0           39   \n",
       "2017-12-01                107     3             -6.2           40   \n",
       "2017-12-01                 78     4             -6.0           36   \n",
       "...                       ...   ...              ...          ...   \n",
       "2018-11-30               1003    19              4.2           34   \n",
       "2018-11-30                764    20              3.4           37   \n",
       "2018-11-30                694    21              2.6           39   \n",
       "2018-11-30                712    22              2.1           41   \n",
       "2018-11-30                584    23              1.9           43   \n",
       "\n",
       "            Wind speed (m/s)  Visibility (10m)  Dew point temperature(°C)  \\\n",
       "Date                                                                        \n",
       "2017-12-01               2.2              2000                      -17.6   \n",
       "2017-12-01               0.8              2000                      -17.6   \n",
       "2017-12-01               1.0              2000                      -17.7   \n",
       "2017-12-01               0.9              2000                      -17.6   \n",
       "2017-12-01               2.3              2000                      -18.6   \n",
       "...                      ...               ...                        ...   \n",
       "2018-11-30               2.6              1894                      -10.3   \n",
       "2018-11-30               2.3              2000                       -9.9   \n",
       "2018-11-30               0.3              1968                       -9.9   \n",
       "2018-11-30               1.0              1859                       -9.8   \n",
       "2018-11-30               1.3              1909                       -9.3   \n",
       "\n",
       "            Solar Radiation (MJ/m2)  Rainfall(mm)  Snowfall (cm) Seasons  \\\n",
       "Date                                                                       \n",
       "2017-12-01                      0.0           0.0            0.0  Winter   \n",
       "2017-12-01                      0.0           0.0            0.0  Winter   \n",
       "2017-12-01                      0.0           0.0            0.0  Winter   \n",
       "2017-12-01                      0.0           0.0            0.0  Winter   \n",
       "2017-12-01                      0.0           0.0            0.0  Winter   \n",
       "...                             ...           ...            ...     ...   \n",
       "2018-11-30                      0.0           0.0            0.0  Autumn   \n",
       "2018-11-30                      0.0           0.0            0.0  Autumn   \n",
       "2018-11-30                      0.0           0.0            0.0  Autumn   \n",
       "2018-11-30                      0.0           0.0            0.0  Autumn   \n",
       "2018-11-30                      0.0           0.0            0.0  Autumn   \n",
       "\n",
       "               Holiday Functioning Day  Day  Month  Year  DayOfWeek  \n",
       "Date                                                                 \n",
       "2017-12-01  No Holiday             Yes    1     12  2017          4  \n",
       "2017-12-01  No Holiday             Yes    1     12  2017          4  \n",
       "2017-12-01  No Holiday             Yes    1     12  2017          4  \n",
       "2017-12-01  No Holiday             Yes    1     12  2017          4  \n",
       "2017-12-01  No Holiday             Yes    1     12  2017          4  \n",
       "...                ...             ...  ...    ...   ...        ...  \n",
       "2018-11-30  No Holiday             Yes   30     11  2018          4  \n",
       "2018-11-30  No Holiday             Yes   30     11  2018          4  \n",
       "2018-11-30  No Holiday             Yes   30     11  2018          4  \n",
       "2018-11-30  No Holiday             Yes   30     11  2018          4  \n",
       "2018-11-30  No Holiday             Yes   30     11  2018          4  \n",
       "\n",
       "[8760 rows x 17 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Day'] = df.index.day\n",
    "df['Month'] = df.index.month\n",
    "df['Year'] = df.index.year\n",
    "df['DayOfWeek']=df.index.dayofweek\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Rented Bike Count</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Wind speed (m/s)</th>\n",
       "      <th>Visibility (10m)</th>\n",
       "      <th>Dew point temperature(°C)</th>\n",
       "      <th>Solar Radiation (MJ/m2)</th>\n",
       "      <th>Rainfall(mm)</th>\n",
       "      <th>Snowfall (cm)</th>\n",
       "      <th>Seasons</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>Functioning Day</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>DayOfWeek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>37</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2000</td>\n",
       "      <td>-17.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2000</td>\n",
       "      <td>-17.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>173</td>\n",
       "      <td>2</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>-17.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>-6.2</td>\n",
       "      <td>40</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2000</td>\n",
       "      <td>-17.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>78</td>\n",
       "      <td>4</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>36</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2000</td>\n",
       "      <td>-18.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8755</th>\n",
       "      <td>2018-11-30</td>\n",
       "      <td>1003</td>\n",
       "      <td>19</td>\n",
       "      <td>4.2</td>\n",
       "      <td>34</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1894</td>\n",
       "      <td>-10.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8756</th>\n",
       "      <td>2018-11-30</td>\n",
       "      <td>764</td>\n",
       "      <td>20</td>\n",
       "      <td>3.4</td>\n",
       "      <td>37</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2000</td>\n",
       "      <td>-9.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8757</th>\n",
       "      <td>2018-11-30</td>\n",
       "      <td>694</td>\n",
       "      <td>21</td>\n",
       "      <td>2.6</td>\n",
       "      <td>39</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1968</td>\n",
       "      <td>-9.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8758</th>\n",
       "      <td>2018-11-30</td>\n",
       "      <td>712</td>\n",
       "      <td>22</td>\n",
       "      <td>2.1</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1859</td>\n",
       "      <td>-9.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8759</th>\n",
       "      <td>2018-11-30</td>\n",
       "      <td>584</td>\n",
       "      <td>23</td>\n",
       "      <td>1.9</td>\n",
       "      <td>43</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1909</td>\n",
       "      <td>-9.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8760 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  Rented Bike Count  Hour  Temperature(°C)  Humidity(%)  \\\n",
       "0    2017-12-01                254     0             -5.2           37   \n",
       "1    2017-12-01                204     1             -5.5           38   \n",
       "2    2017-12-01                173     2             -6.0           39   \n",
       "3    2017-12-01                107     3             -6.2           40   \n",
       "4    2017-12-01                 78     4             -6.0           36   \n",
       "...         ...                ...   ...              ...          ...   \n",
       "8755 2018-11-30               1003    19              4.2           34   \n",
       "8756 2018-11-30                764    20              3.4           37   \n",
       "8757 2018-11-30                694    21              2.6           39   \n",
       "8758 2018-11-30                712    22              2.1           41   \n",
       "8759 2018-11-30                584    23              1.9           43   \n",
       "\n",
       "      Wind speed (m/s)  Visibility (10m)  Dew point temperature(°C)  \\\n",
       "0                  2.2              2000                      -17.6   \n",
       "1                  0.8              2000                      -17.6   \n",
       "2                  1.0              2000                      -17.7   \n",
       "3                  0.9              2000                      -17.6   \n",
       "4                  2.3              2000                      -18.6   \n",
       "...                ...               ...                        ...   \n",
       "8755               2.6              1894                      -10.3   \n",
       "8756               2.3              2000                       -9.9   \n",
       "8757               0.3              1968                       -9.9   \n",
       "8758               1.0              1859                       -9.8   \n",
       "8759               1.3              1909                       -9.3   \n",
       "\n",
       "      Solar Radiation (MJ/m2)  Rainfall(mm)  Snowfall (cm) Seasons  \\\n",
       "0                         0.0           0.0            0.0  Winter   \n",
       "1                         0.0           0.0            0.0  Winter   \n",
       "2                         0.0           0.0            0.0  Winter   \n",
       "3                         0.0           0.0            0.0  Winter   \n",
       "4                         0.0           0.0            0.0  Winter   \n",
       "...                       ...           ...            ...     ...   \n",
       "8755                      0.0           0.0            0.0  Autumn   \n",
       "8756                      0.0           0.0            0.0  Autumn   \n",
       "8757                      0.0           0.0            0.0  Autumn   \n",
       "8758                      0.0           0.0            0.0  Autumn   \n",
       "8759                      0.0           0.0            0.0  Autumn   \n",
       "\n",
       "         Holiday Functioning Day  Day  Month  Year  DayOfWeek  \n",
       "0     No Holiday             Yes    1     12  2017          4  \n",
       "1     No Holiday             Yes    1     12  2017          4  \n",
       "2     No Holiday             Yes    1     12  2017          4  \n",
       "3     No Holiday             Yes    1     12  2017          4  \n",
       "4     No Holiday             Yes    1     12  2017          4  \n",
       "...          ...             ...  ...    ...   ...        ...  \n",
       "8755  No Holiday             Yes   30     11  2018          4  \n",
       "8756  No Holiday             Yes   30     11  2018          4  \n",
       "8757  No Holiday             Yes   30     11  2018          4  \n",
       "8758  No Holiday             Yes   30     11  2018          4  \n",
       "8759  No Holiday             Yes   30     11  2018          4  \n",
       "\n",
       "[8760 rows x 18 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the shape of Dataframe  and Check for Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe Shape: (8760, 18)\n",
      "Any NaN Values Present? False\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataframe Shape:\", df.shape)\n",
    "print(\"Any NaN Values Present?\", df.isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set target variable, Y, as the Daily Rented Bike Count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Target Variable\n",
    "Y = pd.DataFrame(df[\"Rented Bike Count\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set features, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of Y is:  (8760, 1)\n",
      "The shape of X is:  (8760, 17)\n",
      "The 17 features are:  Index(['Rented Bike Count', 'Hour', 'Temperature(°C)', 'Humidity(%)',\n",
      "       'Wind speed (m/s)', 'Visibility (10m)', 'Dew point temperature(°C)',\n",
      "       'Solar Radiation (MJ/m2)', 'Rainfall(mm)', 'Snowfall (cm)', 'Seasons',\n",
      "       'Holiday', 'Functioning Day', 'Day', 'Month', 'Year', 'DayOfWeek'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Selecting the Features\n",
    "X = pd.DataFrame(df.iloc[:,1:])\n",
    "\n",
    "# print(X.shape)\n",
    "print('The shape of Y is: ', Y.shape)\n",
    "print('The shape of X is: ', X.shape)\n",
    "print('The 17 features are: ', X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x0_Autumn', 'x0_Spring', 'x0_Summer', 'x0_Winter',\n",
       "       'x1_No Holiday', 'x2_Yes', 'x3_0', 'x3_1', 'x3_2', 'x3_3', 'x3_4',\n",
       "       'x3_5', 'x3_6'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "categorical = X[[\"Seasons\",\"Holiday\",\"Functioning Day\",\"DayOfWeek\"]]\n",
    "\n",
    "ohe = OneHotEncoder(drop='if_binary', sparse=False)\n",
    "ohe.fit(categorical)\n",
    "ohe.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'categories': 'auto',\n",
       " 'drop': 'if_binary',\n",
       " 'dtype': numpy.float64,\n",
       " 'handle_unknown': 'error',\n",
       " 'sparse': False}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['Autumn', 'Spring', 'Summer', 'Winter'], dtype=object),\n",
       " array(['Holiday', 'No Holiday'], dtype=object),\n",
       " array(['No', 'Yes'], dtype=object),\n",
       " array([0, 1, 2, 3, 4, 5, 6])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 1., 0., 0.],\n",
       "       [1., 0., 0., ..., 1., 0., 0.],\n",
       "       [1., 0., 0., ..., 1., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_encoded = ohe.transform(categorical)\n",
    "categorical_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season_Autumn</th>\n",
       "      <th>Season_Spring</th>\n",
       "      <th>Season_Summer</th>\n",
       "      <th>Season_Winter</th>\n",
       "      <th>Holiday_Yes</th>\n",
       "      <th>Functioning_Day_Yes</th>\n",
       "      <th>DayOfWeek_Sun</th>\n",
       "      <th>DayOfWeek_Mon</th>\n",
       "      <th>DayOfWeek_Tue</th>\n",
       "      <th>DayOfWeek_Wed</th>\n",
       "      <th>DayOfWeek_Thu</th>\n",
       "      <th>DayOfWeek_Fri</th>\n",
       "      <th>DayOfWeek_Sat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8755</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8756</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8757</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8758</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8759</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8760 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Season_Autumn  Season_Spring  Season_Summer  Season_Winter  Holiday_Yes  \\\n",
       "0               0.0            0.0            0.0            1.0          1.0   \n",
       "1               0.0            0.0            0.0            1.0          1.0   \n",
       "2               0.0            0.0            0.0            1.0          1.0   \n",
       "3               0.0            0.0            0.0            1.0          1.0   \n",
       "4               0.0            0.0            0.0            1.0          1.0   \n",
       "...             ...            ...            ...            ...          ...   \n",
       "8755            1.0            0.0            0.0            0.0          1.0   \n",
       "8756            1.0            0.0            0.0            0.0          1.0   \n",
       "8757            1.0            0.0            0.0            0.0          1.0   \n",
       "8758            1.0            0.0            0.0            0.0          1.0   \n",
       "8759            1.0            0.0            0.0            0.0          1.0   \n",
       "\n",
       "      Functioning_Day_Yes  DayOfWeek_Sun  DayOfWeek_Mon  DayOfWeek_Tue  \\\n",
       "0                     1.0            0.0            0.0            0.0   \n",
       "1                     1.0            0.0            0.0            0.0   \n",
       "2                     1.0            0.0            0.0            0.0   \n",
       "3                     1.0            0.0            0.0            0.0   \n",
       "4                     1.0            0.0            0.0            0.0   \n",
       "...                   ...            ...            ...            ...   \n",
       "8755                  1.0            0.0            0.0            0.0   \n",
       "8756                  1.0            0.0            0.0            0.0   \n",
       "8757                  1.0            0.0            0.0            0.0   \n",
       "8758                  1.0            0.0            0.0            0.0   \n",
       "8759                  1.0            0.0            0.0            0.0   \n",
       "\n",
       "      DayOfWeek_Wed  DayOfWeek_Thu  DayOfWeek_Fri  DayOfWeek_Sat  \n",
       "0               0.0            1.0            0.0            0.0  \n",
       "1               0.0            1.0            0.0            0.0  \n",
       "2               0.0            1.0            0.0            0.0  \n",
       "3               0.0            1.0            0.0            0.0  \n",
       "4               0.0            1.0            0.0            0.0  \n",
       "...             ...            ...            ...            ...  \n",
       "8755            0.0            1.0            0.0            0.0  \n",
       "8756            0.0            1.0            0.0            0.0  \n",
       "8757            0.0            1.0            0.0            0.0  \n",
       "8758            0.0            1.0            0.0            0.0  \n",
       "8759            0.0            1.0            0.0            0.0  \n",
       "\n",
       "[8760 rows x 13 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_columns = ['Season_Autumn','Season_Spring','Season_Summer','Season_Winter','Holiday_Yes','Functioning_Day_Yes','DayOfWeek_Sun','DayOfWeek_Mon','DayOfWeek_Tue','DayOfWeek_Wed','DayOfWeek_Thu','DayOfWeek_Fri','DayOfWeek_Sat']\n",
    "categorical_encoded_df = pd.DataFrame(categorical_encoded, columns=cat_columns)\n",
    "categorical_encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rented Bike Count</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Wind speed (m/s)</th>\n",
       "      <th>Visibility (10m)</th>\n",
       "      <th>Dew point temperature(°C)</th>\n",
       "      <th>Solar Radiation (MJ/m2)</th>\n",
       "      <th>Rainfall(mm)</th>\n",
       "      <th>Snowfall (cm)</th>\n",
       "      <th>...</th>\n",
       "      <th>Season_Winter</th>\n",
       "      <th>Holiday_Yes</th>\n",
       "      <th>Functioning_Day_Yes</th>\n",
       "      <th>DayOfWeek_Sun</th>\n",
       "      <th>DayOfWeek_Mon</th>\n",
       "      <th>DayOfWeek_Tue</th>\n",
       "      <th>DayOfWeek_Wed</th>\n",
       "      <th>DayOfWeek_Thu</th>\n",
       "      <th>DayOfWeek_Fri</th>\n",
       "      <th>DayOfWeek_Sat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>37</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2000</td>\n",
       "      <td>-17.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2000</td>\n",
       "      <td>-17.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>173</td>\n",
       "      <td>2</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>-17.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>-6.2</td>\n",
       "      <td>40</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2000</td>\n",
       "      <td>-17.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78</td>\n",
       "      <td>4</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>36</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2000</td>\n",
       "      <td>-18.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8755</th>\n",
       "      <td>1003</td>\n",
       "      <td>19</td>\n",
       "      <td>4.2</td>\n",
       "      <td>34</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1894</td>\n",
       "      <td>-10.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8756</th>\n",
       "      <td>764</td>\n",
       "      <td>20</td>\n",
       "      <td>3.4</td>\n",
       "      <td>37</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2000</td>\n",
       "      <td>-9.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8757</th>\n",
       "      <td>694</td>\n",
       "      <td>21</td>\n",
       "      <td>2.6</td>\n",
       "      <td>39</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1968</td>\n",
       "      <td>-9.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8758</th>\n",
       "      <td>712</td>\n",
       "      <td>22</td>\n",
       "      <td>2.1</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1859</td>\n",
       "      <td>-9.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8759</th>\n",
       "      <td>584</td>\n",
       "      <td>23</td>\n",
       "      <td>1.9</td>\n",
       "      <td>43</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1909</td>\n",
       "      <td>-9.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8760 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Rented Bike Count  Hour  Temperature(°C)  Humidity(%)  Wind speed (m/s)  \\\n",
       "0                   254     0             -5.2           37               2.2   \n",
       "1                   204     1             -5.5           38               0.8   \n",
       "2                   173     2             -6.0           39               1.0   \n",
       "3                   107     3             -6.2           40               0.9   \n",
       "4                    78     4             -6.0           36               2.3   \n",
       "...                 ...   ...              ...          ...               ...   \n",
       "8755               1003    19              4.2           34               2.6   \n",
       "8756                764    20              3.4           37               2.3   \n",
       "8757                694    21              2.6           39               0.3   \n",
       "8758                712    22              2.1           41               1.0   \n",
       "8759                584    23              1.9           43               1.3   \n",
       "\n",
       "      Visibility (10m)  Dew point temperature(°C)  Solar Radiation (MJ/m2)  \\\n",
       "0                 2000                      -17.6                      0.0   \n",
       "1                 2000                      -17.6                      0.0   \n",
       "2                 2000                      -17.7                      0.0   \n",
       "3                 2000                      -17.6                      0.0   \n",
       "4                 2000                      -18.6                      0.0   \n",
       "...                ...                        ...                      ...   \n",
       "8755              1894                      -10.3                      0.0   \n",
       "8756              2000                       -9.9                      0.0   \n",
       "8757              1968                       -9.9                      0.0   \n",
       "8758              1859                       -9.8                      0.0   \n",
       "8759              1909                       -9.3                      0.0   \n",
       "\n",
       "      Rainfall(mm)  Snowfall (cm)  ...  Season_Winter  Holiday_Yes  \\\n",
       "0              0.0            0.0  ...            1.0          1.0   \n",
       "1              0.0            0.0  ...            1.0          1.0   \n",
       "2              0.0            0.0  ...            1.0          1.0   \n",
       "3              0.0            0.0  ...            1.0          1.0   \n",
       "4              0.0            0.0  ...            1.0          1.0   \n",
       "...            ...            ...  ...            ...          ...   \n",
       "8755           0.0            0.0  ...            0.0          1.0   \n",
       "8756           0.0            0.0  ...            0.0          1.0   \n",
       "8757           0.0            0.0  ...            0.0          1.0   \n",
       "8758           0.0            0.0  ...            0.0          1.0   \n",
       "8759           0.0            0.0  ...            0.0          1.0   \n",
       "\n",
       "      Functioning_Day_Yes  DayOfWeek_Sun  DayOfWeek_Mon  DayOfWeek_Tue  \\\n",
       "0                     1.0            0.0            0.0            0.0   \n",
       "1                     1.0            0.0            0.0            0.0   \n",
       "2                     1.0            0.0            0.0            0.0   \n",
       "3                     1.0            0.0            0.0            0.0   \n",
       "4                     1.0            0.0            0.0            0.0   \n",
       "...                   ...            ...            ...            ...   \n",
       "8755                  1.0            0.0            0.0            0.0   \n",
       "8756                  1.0            0.0            0.0            0.0   \n",
       "8757                  1.0            0.0            0.0            0.0   \n",
       "8758                  1.0            0.0            0.0            0.0   \n",
       "8759                  1.0            0.0            0.0            0.0   \n",
       "\n",
       "      DayOfWeek_Wed  DayOfWeek_Thu  DayOfWeek_Fri  DayOfWeek_Sat  \n",
       "0               0.0            1.0            0.0            0.0  \n",
       "1               0.0            1.0            0.0            0.0  \n",
       "2               0.0            1.0            0.0            0.0  \n",
       "3               0.0            1.0            0.0            0.0  \n",
       "4               0.0            1.0            0.0            0.0  \n",
       "...             ...            ...            ...            ...  \n",
       "8755            0.0            1.0            0.0            0.0  \n",
       "8756            0.0            1.0            0.0            0.0  \n",
       "8757            0.0            1.0            0.0            0.0  \n",
       "8758            0.0            1.0            0.0            0.0  \n",
       "8759            0.0            1.0            0.0            0.0  \n",
       "\n",
       "[8760 rows x 26 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.concat([X,categorical_encoded_df], axis=1)\n",
    "X = X.drop(columns=['Seasons','Functioning Day','DayOfWeek','Holiday'])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rented Bike Count              int64\n",
       "Hour                           int64\n",
       "Temperature(°C)              float64\n",
       "Humidity(%)                    int64\n",
       "Wind speed (m/s)             float64\n",
       "Visibility (10m)               int64\n",
       "Dew point temperature(°C)    float64\n",
       "Solar Radiation (MJ/m2)      float64\n",
       "Rainfall(mm)                 float64\n",
       "Snowfall (cm)                float64\n",
       "Day                            int64\n",
       "Month                          int64\n",
       "Year                           int64\n",
       "Season_Autumn                float64\n",
       "Season_Spring                float64\n",
       "Season_Summer                float64\n",
       "Season_Winter                float64\n",
       "Holiday_Yes                  float64\n",
       "Functioning_Day_Yes          float64\n",
       "DayOfWeek_Sun                float64\n",
       "DayOfWeek_Mon                float64\n",
       "DayOfWeek_Tue                float64\n",
       "DayOfWeek_Wed                float64\n",
       "DayOfWeek_Thu                float64\n",
       "DayOfWeek_Fri                float64\n",
       "DayOfWeek_Sat                float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network using Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalise Input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into a train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the train set is: 182208  and the size of the test set is: 45552\n",
      "The ratio is 0.8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Y = np.ravel(Y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.2, shuffle=False ,random_state=42)\n",
    "\n",
    "print(\"The size of the train set is:\", X_train.size, \" and the size of the test set is:\", X_test.size)\n",
    "print(\"The ratio is\", round(X_train.size/(X_test.size+X_train.size), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Neural Network with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-17 03:50:56.783215: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-17 03:50:56.846680: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246/246 [==============================] - 1s 3ms/step - loss: 501.8424 - mae: 501.8424 - val_loss: 371.1022 - val_mae: 371.1021\n",
      "Epoch 2/150\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 160.0265 - mae: 160.0265 - val_loss: 302.3953 - val_mae: 302.3953\n",
      "Epoch 3/150\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 108.5983 - mae: 108.5983 - val_loss: 191.6831 - val_mae: 191.6831\n",
      "Epoch 4/150\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 80.7599 - mae: 80.7599 - val_loss: 173.3949 - val_mae: 173.3949\n",
      "Epoch 5/150\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 60.8933 - mae: 60.8933 - val_loss: 172.6196 - val_mae: 172.6196\n",
      "Epoch 6/150\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 46.5646 - mae: 46.5646 - val_loss: 168.8742 - val_mae: 168.8742\n",
      "Epoch 7/150\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 38.7067 - mae: 38.7067 - val_loss: 177.2263 - val_mae: 177.2263\n",
      "Epoch 8/150\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 32.0182 - mae: 32.0182 - val_loss: 167.7344 - val_mae: 167.7344\n",
      "Epoch 9/150\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 27.2636 - mae: 27.2636 - val_loss: 168.5038 - val_mae: 168.5038\n",
      "Epoch 10/150\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 23.7162 - mae: 23.7162 - val_loss: 172.4746 - val_mae: 172.4746\n",
      "Epoch 11/150\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 20.6608 - mae: 20.6608 - val_loss: 175.9890 - val_mae: 175.9890\n",
      "Epoch 12/150\n",
      "246/246 [==============================] - 0s 814us/step - loss: 19.4967 - mae: 19.4967 - val_loss: 167.6718 - val_mae: 167.6718\n",
      "Epoch 13/150\n",
      "246/246 [==============================] - 0s 681us/step - loss: 17.1486 - mae: 17.1486 - val_loss: 165.7533 - val_mae: 165.7533\n",
      "Epoch 14/150\n",
      "246/246 [==============================] - 0s 701us/step - loss: 14.4515 - mae: 14.4515 - val_loss: 166.8808 - val_mae: 166.8808\n",
      "Epoch 15/150\n",
      "246/246 [==============================] - 0s 703us/step - loss: 13.0480 - mae: 13.0480 - val_loss: 168.2172 - val_mae: 168.2172\n",
      "Epoch 16/150\n",
      "246/246 [==============================] - 0s 658us/step - loss: 12.2719 - mae: 12.2719 - val_loss: 173.5762 - val_mae: 173.5762\n",
      "Epoch 17/150\n",
      "246/246 [==============================] - 0s 678us/step - loss: 12.0757 - mae: 12.0757 - val_loss: 164.9205 - val_mae: 164.9205\n",
      "Epoch 18/150\n",
      "246/246 [==============================] - 0s 697us/step - loss: 10.6817 - mae: 10.6817 - val_loss: 164.7311 - val_mae: 164.7311\n",
      "Epoch 19/150\n",
      "246/246 [==============================] - 0s 732us/step - loss: 10.5098 - mae: 10.5098 - val_loss: 165.7633 - val_mae: 165.7633\n",
      "Epoch 20/150\n",
      "246/246 [==============================] - 0s 731us/step - loss: 9.0583 - mae: 9.0583 - val_loss: 163.8502 - val_mae: 163.8502\n",
      "Epoch 21/150\n",
      "246/246 [==============================] - 0s 717us/step - loss: 8.8945 - mae: 8.8945 - val_loss: 163.9599 - val_mae: 163.9599\n",
      "Epoch 22/150\n",
      "246/246 [==============================] - 0s 756us/step - loss: 7.7949 - mae: 7.7949 - val_loss: 163.4742 - val_mae: 163.4742\n",
      "Epoch 23/150\n",
      "246/246 [==============================] - 0s 753us/step - loss: 7.7590 - mae: 7.7590 - val_loss: 167.8179 - val_mae: 167.8179\n",
      "Epoch 24/150\n",
      "246/246 [==============================] - 0s 658us/step - loss: 7.8573 - mae: 7.8573 - val_loss: 167.8015 - val_mae: 167.8015\n",
      "Epoch 25/150\n",
      "246/246 [==============================] - 0s 641us/step - loss: 8.6968 - mae: 8.6968 - val_loss: 169.1544 - val_mae: 169.1544\n",
      "Epoch 26/150\n",
      "246/246 [==============================] - 0s 661us/step - loss: 7.4367 - mae: 7.4367 - val_loss: 165.6395 - val_mae: 165.6395\n",
      "Epoch 27/150\n",
      "246/246 [==============================] - 0s 665us/step - loss: 6.0294 - mae: 6.0294 - val_loss: 165.3846 - val_mae: 165.3846\n",
      "Epoch 28/150\n",
      "246/246 [==============================] - 0s 678us/step - loss: 7.2557 - mae: 7.2557 - val_loss: 166.5046 - val_mae: 166.5046\n",
      "Epoch 29/150\n",
      "246/246 [==============================] - 0s 678us/step - loss: 5.4295 - mae: 5.4295 - val_loss: 168.2959 - val_mae: 168.2959\n",
      "Epoch 30/150\n",
      "246/246 [==============================] - 0s 673us/step - loss: 5.5274 - mae: 5.5274 - val_loss: 163.3880 - val_mae: 163.3880\n",
      "Epoch 31/150\n",
      "246/246 [==============================] - 0s 654us/step - loss: 5.2752 - mae: 5.2752 - val_loss: 164.2023 - val_mae: 164.2023\n",
      "Epoch 32/150\n",
      "246/246 [==============================] - 0s 639us/step - loss: 4.9012 - mae: 4.9012 - val_loss: 164.5378 - val_mae: 164.5378\n",
      "Epoch 33/150\n",
      "246/246 [==============================] - 0s 644us/step - loss: 4.8845 - mae: 4.8845 - val_loss: 171.0327 - val_mae: 171.0327\n",
      "Epoch 34/150\n",
      "246/246 [==============================] - 0s 642us/step - loss: 4.7452 - mae: 4.7452 - val_loss: 164.5363 - val_mae: 164.5363\n",
      "Epoch 35/150\n",
      "246/246 [==============================] - 0s 641us/step - loss: 4.7174 - mae: 4.7174 - val_loss: 165.4807 - val_mae: 165.4807\n",
      "Epoch 36/150\n",
      "246/246 [==============================] - 0s 639us/step - loss: 4.6062 - mae: 4.6062 - val_loss: 167.2719 - val_mae: 167.2719\n",
      "Epoch 37/150\n",
      "246/246 [==============================] - 0s 641us/step - loss: 4.9536 - mae: 4.9536 - val_loss: 164.0410 - val_mae: 164.0410\n",
      "Epoch 38/150\n",
      "246/246 [==============================] - 0s 864us/step - loss: 3.8648 - mae: 3.8648 - val_loss: 163.8307 - val_mae: 163.8307\n",
      "Epoch 39/150\n",
      "246/246 [==============================] - 0s 830us/step - loss: 3.7619 - mae: 3.7619 - val_loss: 169.6737 - val_mae: 169.6737\n",
      "Epoch 40/150\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 4.3147 - mae: 4.3147 - val_loss: 168.2274 - val_mae: 168.2274\n",
      "Epoch 41/150\n",
      "246/246 [==============================] - 0s 769us/step - loss: 4.5859 - mae: 4.5859 - val_loss: 167.3493 - val_mae: 167.3493\n",
      "Epoch 42/150\n",
      "246/246 [==============================] - 0s 761us/step - loss: 4.0267 - mae: 4.0267 - val_loss: 163.1995 - val_mae: 163.1995\n",
      "Epoch 43/150\n",
      "246/246 [==============================] - 0s 880us/step - loss: 4.1063 - mae: 4.1063 - val_loss: 163.7111 - val_mae: 163.7111\n",
      "Epoch 44/150\n",
      "246/246 [==============================] - 0s 741us/step - loss: 3.8005 - mae: 3.8005 - val_loss: 165.9123 - val_mae: 165.9123\n",
      "Epoch 45/150\n",
      "246/246 [==============================] - 0s 709us/step - loss: 3.5201 - mae: 3.5201 - val_loss: 165.8487 - val_mae: 165.8487\n",
      "Epoch 46/150\n",
      "246/246 [==============================] - 0s 656us/step - loss: 3.4546 - mae: 3.4546 - val_loss: 164.6363 - val_mae: 164.6363\n",
      "Epoch 47/150\n",
      "246/246 [==============================] - 0s 945us/step - loss: 3.8980 - mae: 3.8980 - val_loss: 167.0089 - val_mae: 167.0089\n",
      "Epoch 48/150\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3.4771 - mae: 3.4771 - val_loss: 164.2201 - val_mae: 164.2201\n",
      "Epoch 49/150\n",
      "246/246 [==============================] - 0s 933us/step - loss: 3.9923 - mae: 3.9923 - val_loss: 164.9059 - val_mae: 164.9059\n",
      "Epoch 50/150\n",
      "246/246 [==============================] - 0s 720us/step - loss: 4.1858 - mae: 4.1858 - val_loss: 164.9696 - val_mae: 164.9696\n",
      "Epoch 51/150\n",
      "246/246 [==============================] - 0s 662us/step - loss: 4.4404 - mae: 4.4404 - val_loss: 162.8340 - val_mae: 162.8340\n",
      "Epoch 52/150\n",
      "246/246 [==============================] - 0s 660us/step - loss: 3.2767 - mae: 3.2767 - val_loss: 163.5168 - val_mae: 163.5168\n",
      "Epoch 53/150\n",
      "246/246 [==============================] - 0s 805us/step - loss: 3.6325 - mae: 3.6325 - val_loss: 163.1377 - val_mae: 163.1377\n",
      "Epoch 54/150\n",
      "246/246 [==============================] - 0s 648us/step - loss: 3.9632 - mae: 3.9632 - val_loss: 163.9832 - val_mae: 163.9832\n",
      "Epoch 55/150\n",
      "246/246 [==============================] - 0s 639us/step - loss: 3.2232 - mae: 3.2232 - val_loss: 167.8117 - val_mae: 167.8117\n",
      "Epoch 56/150\n",
      "246/246 [==============================] - 0s 648us/step - loss: 2.8900 - mae: 2.8900 - val_loss: 162.7812 - val_mae: 162.7812\n",
      "Epoch 57/150\n",
      "246/246 [==============================] - 0s 648us/step - loss: 2.7327 - mae: 2.7327 - val_loss: 163.0920 - val_mae: 163.0920\n",
      "Epoch 58/150\n",
      "246/246 [==============================] - 0s 642us/step - loss: 3.0198 - mae: 3.0198 - val_loss: 164.0571 - val_mae: 164.0571\n",
      "Epoch 59/150\n",
      "246/246 [==============================] - 0s 790us/step - loss: 3.4030 - mae: 3.4030 - val_loss: 163.1227 - val_mae: 163.1227\n",
      "Epoch 60/150\n",
      "246/246 [==============================] - 0s 703us/step - loss: 3.2663 - mae: 3.2663 - val_loss: 164.4241 - val_mae: 164.4241\n",
      "Epoch 61/150\n",
      "246/246 [==============================] - 0s 689us/step - loss: 2.6591 - mae: 2.6591 - val_loss: 162.8004 - val_mae: 162.8004\n",
      "Epoch 62/150\n",
      "246/246 [==============================] - 0s 812us/step - loss: 3.7303 - mae: 3.7303 - val_loss: 163.9494 - val_mae: 163.9494\n",
      "Epoch 63/150\n",
      "246/246 [==============================] - 0s 646us/step - loss: 3.0727 - mae: 3.0727 - val_loss: 162.0972 - val_mae: 162.0972\n",
      "Epoch 64/150\n",
      "246/246 [==============================] - 0s 877us/step - loss: 3.2623 - mae: 3.2623 - val_loss: 163.1124 - val_mae: 163.1124\n",
      "Epoch 65/150\n",
      "246/246 [==============================] - 0s 675us/step - loss: 3.3930 - mae: 3.3930 - val_loss: 162.9912 - val_mae: 162.9912\n",
      "Epoch 66/150\n",
      "246/246 [==============================] - 0s 764us/step - loss: 3.2518 - mae: 3.2518 - val_loss: 173.6536 - val_mae: 173.6536\n",
      "Epoch 67/150\n",
      "246/246 [==============================] - 0s 643us/step - loss: 4.8605 - mae: 4.8605 - val_loss: 162.3777 - val_mae: 162.3777\n",
      "Epoch 68/150\n",
      "246/246 [==============================] - 0s 647us/step - loss: 3.1675 - mae: 3.1675 - val_loss: 161.4946 - val_mae: 161.4946\n",
      "Epoch 69/150\n",
      "246/246 [==============================] - 0s 803us/step - loss: 2.9631 - mae: 2.9631 - val_loss: 164.4545 - val_mae: 164.4545\n",
      "Epoch 70/150\n",
      "246/246 [==============================] - 0s 645us/step - loss: 3.1265 - mae: 3.1265 - val_loss: 162.1700 - val_mae: 162.1700\n",
      "Epoch 71/150\n",
      "246/246 [==============================] - 0s 849us/step - loss: 2.4189 - mae: 2.4189 - val_loss: 164.6954 - val_mae: 164.6954\n",
      "Epoch 72/150\n",
      "246/246 [==============================] - 0s 644us/step - loss: 2.5322 - mae: 2.5322 - val_loss: 164.9122 - val_mae: 164.9122\n",
      "Epoch 73/150\n",
      "246/246 [==============================] - 0s 644us/step - loss: 3.1790 - mae: 3.1790 - val_loss: 162.7641 - val_mae: 162.7641\n",
      "Epoch 74/150\n",
      "246/246 [==============================] - 0s 925us/step - loss: 3.4388 - mae: 3.4388 - val_loss: 162.2580 - val_mae: 162.2580\n",
      "Epoch 75/150\n",
      "246/246 [==============================] - 0s 711us/step - loss: 3.1571 - mae: 3.1571 - val_loss: 163.3423 - val_mae: 163.3423\n",
      "Epoch 76/150\n",
      "246/246 [==============================] - 0s 872us/step - loss: 4.2381 - mae: 4.2381 - val_loss: 163.0642 - val_mae: 163.0642\n",
      "Epoch 77/150\n",
      "246/246 [==============================] - 0s 892us/step - loss: 2.8580 - mae: 2.8580 - val_loss: 164.6479 - val_mae: 164.6479\n",
      "Epoch 78/150\n",
      "246/246 [==============================] - 0s 696us/step - loss: 3.1482 - mae: 3.1482 - val_loss: 166.3800 - val_mae: 166.3800\n",
      "Epoch 79/150\n",
      "246/246 [==============================] - 0s 819us/step - loss: 3.0995 - mae: 3.0995 - val_loss: 161.2838 - val_mae: 161.2838\n",
      "Epoch 80/150\n",
      "246/246 [==============================] - 0s 650us/step - loss: 3.5622 - mae: 3.5622 - val_loss: 163.2088 - val_mae: 163.2088\n",
      "Epoch 81/150\n",
      "246/246 [==============================] - 0s 766us/step - loss: 3.0095 - mae: 3.0095 - val_loss: 160.8335 - val_mae: 160.8335\n",
      "Epoch 82/150\n",
      "246/246 [==============================] - 0s 641us/step - loss: 2.5604 - mae: 2.5604 - val_loss: 161.4997 - val_mae: 161.4997\n",
      "Epoch 83/150\n",
      "246/246 [==============================] - 0s 650us/step - loss: 3.0650 - mae: 3.0650 - val_loss: 162.3738 - val_mae: 162.3738\n",
      "Epoch 84/150\n",
      "246/246 [==============================] - 0s 882us/step - loss: 2.9966 - mae: 2.9966 - val_loss: 160.5502 - val_mae: 160.5502\n",
      "Epoch 85/150\n",
      "246/246 [==============================] - 0s 666us/step - loss: 3.6544 - mae: 3.6544 - val_loss: 161.0020 - val_mae: 161.0020\n",
      "Epoch 86/150\n",
      "246/246 [==============================] - 0s 853us/step - loss: 3.3596 - mae: 3.3596 - val_loss: 161.6864 - val_mae: 161.6864\n",
      "Epoch 87/150\n",
      "246/246 [==============================] - 0s 847us/step - loss: 3.4496 - mae: 3.4496 - val_loss: 163.0115 - val_mae: 163.0115\n",
      "Epoch 88/150\n",
      "246/246 [==============================] - 0s 650us/step - loss: 2.6702 - mae: 2.6702 - val_loss: 160.9723 - val_mae: 160.9723\n",
      "Epoch 89/150\n",
      "246/246 [==============================] - 0s 803us/step - loss: 2.9075 - mae: 2.9075 - val_loss: 163.9722 - val_mae: 163.9722\n",
      "Epoch 90/150\n",
      "246/246 [==============================] - 0s 643us/step - loss: 3.6039 - mae: 3.6039 - val_loss: 163.8566 - val_mae: 163.8566\n",
      "Epoch 91/150\n",
      "246/246 [==============================] - 0s 785us/step - loss: 2.5805 - mae: 2.5805 - val_loss: 161.4124 - val_mae: 161.4125\n",
      "Epoch 92/150\n",
      "246/246 [==============================] - 0s 640us/step - loss: 3.2149 - mae: 3.2149 - val_loss: 164.1197 - val_mae: 164.1197\n",
      "Epoch 93/150\n",
      "246/246 [==============================] - 0s 638us/step - loss: 4.0102 - mae: 4.0102 - val_loss: 160.3168 - val_mae: 160.3168\n",
      "Epoch 94/150\n",
      "246/246 [==============================] - 0s 803us/step - loss: 2.8088 - mae: 2.8088 - val_loss: 162.8248 - val_mae: 162.8248\n",
      "Epoch 95/150\n",
      "246/246 [==============================] - 0s 639us/step - loss: 2.4858 - mae: 2.4858 - val_loss: 160.7494 - val_mae: 160.7494\n",
      "Epoch 96/150\n",
      "246/246 [==============================] - 0s 791us/step - loss: 2.6996 - mae: 2.6996 - val_loss: 160.1246 - val_mae: 160.1246\n",
      "Epoch 97/150\n",
      "246/246 [==============================] - 0s 653us/step - loss: 3.4372 - mae: 3.4372 - val_loss: 159.7489 - val_mae: 159.7489\n",
      "Epoch 98/150\n",
      "246/246 [==============================] - 0s 666us/step - loss: 2.4511 - mae: 2.4511 - val_loss: 161.1600 - val_mae: 161.1600\n",
      "Epoch 99/150\n",
      "246/246 [==============================] - 0s 916us/step - loss: 2.9603 - mae: 2.9603 - val_loss: 165.2752 - val_mae: 165.2752\n",
      "Epoch 100/150\n",
      "246/246 [==============================] - 0s 734us/step - loss: 3.4383 - mae: 3.4383 - val_loss: 160.1077 - val_mae: 160.1077\n",
      "Epoch 101/150\n",
      "246/246 [==============================] - 0s 836us/step - loss: 2.4413 - mae: 2.4413 - val_loss: 160.8108 - val_mae: 160.8108\n",
      "Epoch 102/150\n",
      "246/246 [==============================] - 0s 648us/step - loss: 2.9268 - mae: 2.9268 - val_loss: 161.3740 - val_mae: 161.3740\n",
      "Epoch 103/150\n",
      "246/246 [==============================] - 0s 763us/step - loss: 3.1633 - mae: 3.1633 - val_loss: 160.5241 - val_mae: 160.5241\n",
      "Epoch 104/150\n",
      "246/246 [==============================] - 0s 641us/step - loss: 3.3290 - mae: 3.3290 - val_loss: 162.4552 - val_mae: 162.4552\n",
      "Epoch 105/150\n",
      "246/246 [==============================] - 0s 645us/step - loss: 2.9170 - mae: 2.9170 - val_loss: 159.4198 - val_mae: 159.4198\n",
      "Epoch 106/150\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 2.6988 - mae: 2.6988 - val_loss: 159.9745 - val_mae: 159.9745\n",
      "Epoch 107/150\n",
      "246/246 [==============================] - 0s 995us/step - loss: 2.3911 - mae: 2.3911 - val_loss: 163.5565 - val_mae: 163.5565\n",
      "Epoch 108/150\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3.0579 - mae: 3.0579 - val_loss: 162.5835 - val_mae: 162.5835\n",
      "Epoch 109/150\n",
      "246/246 [==============================] - 0s 829us/step - loss: 2.7237 - mae: 2.7237 - val_loss: 165.7160 - val_mae: 165.7160\n",
      "Epoch 110/150\n",
      "246/246 [==============================] - 0s 830us/step - loss: 3.7459 - mae: 3.7459 - val_loss: 159.0253 - val_mae: 159.0253\n",
      "Epoch 111/150\n",
      "246/246 [==============================] - 0s 754us/step - loss: 2.2164 - mae: 2.2164 - val_loss: 161.8737 - val_mae: 161.8737\n",
      "Epoch 112/150\n",
      "246/246 [==============================] - 0s 877us/step - loss: 3.0482 - mae: 3.0482 - val_loss: 158.9211 - val_mae: 158.9211\n",
      "Epoch 113/150\n",
      "246/246 [==============================] - 0s 771us/step - loss: 2.9959 - mae: 2.9959 - val_loss: 158.8580 - val_mae: 158.8580\n",
      "Epoch 114/150\n",
      "246/246 [==============================] - 0s 669us/step - loss: 3.4669 - mae: 3.4669 - val_loss: 159.1187 - val_mae: 159.1187\n",
      "Epoch 115/150\n",
      "246/246 [==============================] - 0s 970us/step - loss: 2.7385 - mae: 2.7385 - val_loss: 159.6394 - val_mae: 159.6394\n",
      "Epoch 116/150\n",
      "246/246 [==============================] - 0s 648us/step - loss: 2.3229 - mae: 2.3229 - val_loss: 161.4949 - val_mae: 161.4949\n",
      "Epoch 117/150\n",
      "246/246 [==============================] - 0s 705us/step - loss: 2.6238 - mae: 2.6238 - val_loss: 162.5694 - val_mae: 162.5694\n",
      "Epoch 118/150\n",
      "246/246 [==============================] - 0s 919us/step - loss: 2.4934 - mae: 2.4934 - val_loss: 158.4449 - val_mae: 158.4449\n",
      "Epoch 119/150\n",
      "246/246 [==============================] - 0s 665us/step - loss: 2.2781 - mae: 2.2781 - val_loss: 158.1825 - val_mae: 158.1825\n",
      "Epoch 120/150\n",
      "246/246 [==============================] - 0s 771us/step - loss: 2.7781 - mae: 2.7781 - val_loss: 159.4580 - val_mae: 159.4580\n",
      "Epoch 121/150\n",
      "246/246 [==============================] - 0s 645us/step - loss: 3.0270 - mae: 3.0270 - val_loss: 162.9089 - val_mae: 162.9089\n",
      "Epoch 122/150\n",
      "246/246 [==============================] - 0s 647us/step - loss: 2.7449 - mae: 2.7449 - val_loss: 159.1193 - val_mae: 159.1193\n",
      "Epoch 123/150\n",
      "246/246 [==============================] - 0s 894us/step - loss: 3.0018 - mae: 3.0018 - val_loss: 158.3002 - val_mae: 158.3002\n",
      "Epoch 124/150\n",
      "246/246 [==============================] - 0s 729us/step - loss: 2.7716 - mae: 2.7716 - val_loss: 159.6350 - val_mae: 159.6350\n",
      "Epoch 125/150\n",
      "246/246 [==============================] - 0s 789us/step - loss: 2.2905 - mae: 2.2905 - val_loss: 157.9567 - val_mae: 157.9567\n",
      "Epoch 126/150\n",
      "246/246 [==============================] - 0s 644us/step - loss: 2.4787 - mae: 2.4787 - val_loss: 158.8188 - val_mae: 158.8188\n",
      "Epoch 127/150\n",
      "246/246 [==============================] - 0s 646us/step - loss: 2.4664 - mae: 2.4664 - val_loss: 159.0833 - val_mae: 159.0833\n",
      "Epoch 128/150\n",
      "246/246 [==============================] - 0s 801us/step - loss: 2.7817 - mae: 2.7817 - val_loss: 159.2596 - val_mae: 159.2596\n",
      "Epoch 129/150\n",
      "246/246 [==============================] - 0s 642us/step - loss: 2.3536 - mae: 2.3536 - val_loss: 158.5225 - val_mae: 158.5225\n",
      "Epoch 130/150\n",
      "246/246 [==============================] - 0s 773us/step - loss: 2.4249 - mae: 2.4249 - val_loss: 165.4096 - val_mae: 165.4096\n",
      "Epoch 131/150\n",
      "246/246 [==============================] - 0s 645us/step - loss: 3.0830 - mae: 3.0830 - val_loss: 158.6873 - val_mae: 158.6873\n",
      "Epoch 132/150\n",
      "246/246 [==============================] - 0s 640us/step - loss: 3.1996 - mae: 3.1996 - val_loss: 163.1646 - val_mae: 163.1646\n",
      "Epoch 133/150\n",
      "246/246 [==============================] - 0s 794us/step - loss: 2.5541 - mae: 2.5541 - val_loss: 158.8328 - val_mae: 158.8328\n",
      "Epoch 134/150\n",
      "246/246 [==============================] - 0s 715us/step - loss: 2.7024 - mae: 2.7024 - val_loss: 158.8472 - val_mae: 158.8472\n",
      "Epoch 135/150\n",
      "246/246 [==============================] - 0s 643us/step - loss: 2.7562 - mae: 2.7562 - val_loss: 163.2433 - val_mae: 163.2433\n",
      "Epoch 136/150\n",
      "246/246 [==============================] - 0s 805us/step - loss: 2.5217 - mae: 2.5217 - val_loss: 163.1881 - val_mae: 163.1881\n",
      "Epoch 137/150\n",
      "246/246 [==============================] - 0s 646us/step - loss: 2.8832 - mae: 2.8832 - val_loss: 158.0663 - val_mae: 158.0663\n",
      "Epoch 138/150\n",
      "246/246 [==============================] - 0s 803us/step - loss: 2.7098 - mae: 2.7098 - val_loss: 159.3808 - val_mae: 159.3808\n",
      "Epoch 139/150\n",
      "246/246 [==============================] - 0s 651us/step - loss: 2.4635 - mae: 2.4635 - val_loss: 158.4771 - val_mae: 158.4771\n",
      "Epoch 140/150\n",
      "246/246 [==============================] - 0s 766us/step - loss: 2.6736 - mae: 2.6736 - val_loss: 161.2669 - val_mae: 161.2669\n",
      "Epoch 141/150\n",
      "246/246 [==============================] - 0s 651us/step - loss: 2.7291 - mae: 2.7291 - val_loss: 157.9702 - val_mae: 157.9702\n",
      "Epoch 142/150\n",
      "246/246 [==============================] - 0s 668us/step - loss: 2.2776 - mae: 2.2776 - val_loss: 159.6911 - val_mae: 159.6911\n",
      "Epoch 143/150\n",
      "246/246 [==============================] - 0s 809us/step - loss: 2.5510 - mae: 2.5510 - val_loss: 163.7327 - val_mae: 163.7327\n",
      "Epoch 144/150\n",
      "246/246 [==============================] - 0s 651us/step - loss: 3.3450 - mae: 3.3450 - val_loss: 159.5459 - val_mae: 159.5459\n",
      "Epoch 145/150\n",
      "246/246 [==============================] - 0s 817us/step - loss: 2.3249 - mae: 2.3249 - val_loss: 162.0711 - val_mae: 162.0711\n",
      "Epoch 146/150\n",
      "246/246 [==============================] - 0s 899us/step - loss: 3.0234 - mae: 3.0234 - val_loss: 161.1801 - val_mae: 161.1801\n",
      "Epoch 147/150\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 2.4725 - mae: 2.4725 - val_loss: 159.7487 - val_mae: 159.7487\n",
      "Epoch 148/150\n",
      "246/246 [==============================] - 0s 708us/step - loss: 2.7339 - mae: 2.7339 - val_loss: 158.1723 - val_mae: 158.1723\n",
      "Epoch 149/150\n",
      "246/246 [==============================] - 0s 768us/step - loss: 2.4922 - mae: 2.4922 - val_loss: 162.7419 - val_mae: 162.7419\n",
      "Epoch 150/150\n",
      "246/246 [==============================] - 0s 646us/step - loss: 2.6814 - mae: 2.6814 - val_loss: 158.9193 - val_mae: 158.9193\n",
      "Duration: 0:00:30.328736\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "# Building model\n",
    "model = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "model.add(Dense(units = 8, activation = 'relu', input_dim = 26))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "model.add(Dense(units = 24, activation = 'relu'))\n",
    "\n",
    "# Adding the third hidden layer\n",
    "model.add(Dense(units = 60, activation = 'relu'))\n",
    "\n",
    "# Adding the fourth hidden layer\n",
    "model.add(Dense(units = 24, activation = 'relu'))\n",
    "\n",
    "# Adding the fifth hidden layer\n",
    "model.add(Dense(units = 52, activation = 'relu'))\n",
    "\n",
    "#avoids overfitting\n",
    "#https://keras.io/api/layers/regularization_layers/dropout/\n",
    "model.add(keras.layers.Dropout(0.0001))\n",
    "\n",
    "# Adding the output layer\n",
    "\n",
    "model.add(Dense(units = 1))\n",
    "\n",
    "\n",
    "# Compiling the ANN\n",
    "model.compile(optimizer = 'adam', loss = 'mae', metrics=['mae'])#metrics tracks values but doesn't decide with it\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "history = model.fit(X_train, y_train, batch_size = 20, epochs = 150, validation_split=0.3)\n",
    "\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot learning curves\n",
    "\n",
    "#accuracy no idea what this is for\n",
    "plt.plot(history.history['mae'])\n",
    "plt.plot(history.history['val_mae'])\n",
    "plt.title('model mean absolute error')\n",
    "plt.ylabel('mae')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['mae', 'Validation mae'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "#loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss','Val Loss'], loc='upper left')#, 'Validation Loss'\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 0s 905us/step - loss: 595.3682 - mae: 595.3682\n",
      "55/55 [==============================] - 0s 425us/step - loss: 595.3682 - mae: 595.3682\n"
     ]
    }
   ],
   "source": [
    "#model evaluation\n",
    "score = model.evaluate(X_test, y_test)[1] # Accuracy\n",
    "score2= model.evaluate(X_test, y_test)[0] # Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy without tuning: 595.3681640625\n",
      "Loss without tuning: 595.3681640625\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy without tuning: {}'.format(score))\n",
    "print('Loss without tuning: {}'.format(score2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8)                 216       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 24)                216       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 60)                1500      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 24)                1464      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 52)                1300      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 52)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 53        \n",
      "=================================================================\n",
      "Total params: 4,749\n",
      "Trainable params: 4,749\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "plt.plot(y_test, color = 'red', label = 'Real data')\n",
    "plt.plot(y_pred, color = 'blue', label = 'Predicted data')\n",
    "plt.title('Prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 595.3682529826593\n",
      "Mean Squared Error: 504732.8287137423\n",
      "Root Mean Squared Error: 710.4455142470408\n"
     ]
    }
   ],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HP Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "from keras_tuner import HyperModel\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    for i in range(hp.Int('num_layers', 4, 4)): #2 to 20 hidden layers\n",
    "        model.add(Dense(units=hp.Int('units_' + str(i),\n",
    "                                            min_value=4,\n",
    "                                            max_value=64, #no. of neurons tested is between 32 and 512\n",
    "                                            step=4),\n",
    "                               activation= hp.Choice('dense_activation', \n",
    "                                                     values=['relu']))) # , 'tanh','sigmoid'\n",
    "    \n",
    "    model.add(\n",
    "        keras.layers.Dropout(\n",
    "            hp.Float(\n",
    "                    'dropout',\n",
    "                    min_value=0.0001,\n",
    "                    max_value=0.1,\n",
    "                    step=0.01)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Adding the output layer\n",
    "    model.add(Dense(units = 1, activation = 'linear'))\n",
    "\n",
    "\n",
    "    model.compile(\n",
    "        #optimizer='adam',\n",
    "        optimizer = hp.Choice('dense_optimizer',\n",
    "                values=['adam'] ), # ,'SGD','rmsprop','adadelta'\n",
    "        loss = 'mae',\n",
    "        metrics = ['mae']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_rs = kt.tuners.RandomSearch(\n",
    "            build_model,\n",
    "            objective='val_loss',\n",
    "            max_trials=200,\n",
    "            executions_per_trial=2, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6 Complete [00h 00m 54s]\n",
      "val_loss: 40.17098045349121\n",
      "\n",
      "Best val_loss So Far: 4.19793438911438\n",
      "Total elapsed time: 00h 05m 16s\n",
      "\n",
      "Search: Running Trial #7\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "num_layers        |4                 |4                 \n",
      "units_0           |12                |52                \n",
      "dense_activation  |relu              |relu              \n",
      "units_1           |40                |40                \n",
      "units_2           |44                |32                \n",
      "units_3           |44                |64                \n",
      "dropout           |0.0901            |0.0101            \n",
      "dense_optimizer   |adam              |adam              \n",
      "\n",
      "Epoch 1/200\n",
      "154/154 [==============================] - 1s 2ms/step - loss: 644.2829 - mae: 644.2829 - val_loss: 367.9876 - val_mae: 367.9876\n",
      "Epoch 2/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 338.4486 - mae: 338.4486 - val_loss: 272.2076 - val_mae: 272.2076\n",
      "Epoch 3/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 241.6069 - mae: 241.6069 - val_loss: 209.7358 - val_mae: 209.7358\n",
      "Epoch 4/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 192.2528 - mae: 192.2528 - val_loss: 146.8941 - val_mae: 146.8941\n",
      "Epoch 5/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 131.9751 - mae: 131.9751 - val_loss: 82.5989 - val_mae: 82.5989\n",
      "Epoch 6/200\n",
      "154/154 [==============================] - 0s 952us/step - loss: 92.3539 - mae: 92.3539 - val_loss: 65.8470 - val_mae: 65.8470\n",
      "Epoch 7/200\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 83.1983 - mae: 83.1983 - val_loss: 59.4184 - val_mae: 59.4184\n",
      "Epoch 8/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 75.9155 - mae: 75.9155 - val_loss: 50.4226 - val_mae: 50.4226\n",
      "Epoch 9/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 72.1660 - mae: 72.1660 - val_loss: 47.4425 - val_mae: 47.4425\n",
      "Epoch 10/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 69.5125 - mae: 69.5125 - val_loss: 43.9573 - val_mae: 43.9573\n",
      "Epoch 11/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 67.7985 - mae: 67.7985 - val_loss: 41.9688 - val_mae: 41.9688\n",
      "Epoch 12/200\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 66.3001 - mae: 66.3001 - val_loss: 41.8089 - val_mae: 41.8089\n",
      "Epoch 13/200\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 63.3158 - mae: 63.3158 - val_loss: 37.3349 - val_mae: 37.3349\n",
      "Epoch 14/200\n",
      "154/154 [==============================] - 0s 884us/step - loss: 58.5691 - mae: 58.5691 - val_loss: 38.5305 - val_mae: 38.5305\n",
      "Epoch 15/200\n",
      "154/154 [==============================] - 0s 765us/step - loss: 58.3624 - mae: 58.3624 - val_loss: 33.4824 - val_mae: 33.4824\n",
      "Epoch 16/200\n",
      "154/154 [==============================] - 0s 764us/step - loss: 57.1926 - mae: 57.1926 - val_loss: 34.3089 - val_mae: 34.3089\n",
      "Epoch 17/200\n",
      "154/154 [==============================] - 0s 796us/step - loss: 58.1987 - mae: 58.1987 - val_loss: 35.8603 - val_mae: 35.8603\n",
      "Epoch 18/200\n",
      "154/154 [==============================] - 0s 778us/step - loss: 53.2469 - mae: 53.2469 - val_loss: 30.4228 - val_mae: 30.4228\n",
      "Epoch 19/200\n",
      "154/154 [==============================] - 0s 757us/step - loss: 52.3736 - mae: 52.3736 - val_loss: 39.9160 - val_mae: 39.9160\n",
      "Epoch 20/200\n",
      "154/154 [==============================] - 0s 766us/step - loss: 51.7551 - mae: 51.7551 - val_loss: 32.6276 - val_mae: 32.6276\n",
      "Epoch 21/200\n",
      "154/154 [==============================] - 0s 766us/step - loss: 52.3286 - mae: 52.3286 - val_loss: 28.3385 - val_mae: 28.3385\n",
      "Epoch 22/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 51.5521 - mae: 51.5521 - val_loss: 28.1715 - val_mae: 28.1715\n",
      "Epoch 23/200\n",
      "154/154 [==============================] - 0s 758us/step - loss: 49.7003 - mae: 49.7003 - val_loss: 24.9336 - val_mae: 24.9336\n",
      "Epoch 24/200\n",
      "154/154 [==============================] - 0s 782us/step - loss: 46.5310 - mae: 46.5310 - val_loss: 36.4562 - val_mae: 36.4562\n",
      "Epoch 25/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 49.6695 - mae: 49.6695 - val_loss: 24.6702 - val_mae: 24.6702\n",
      "Epoch 26/200\n",
      "154/154 [==============================] - 0s 766us/step - loss: 47.4897 - mae: 47.4897 - val_loss: 21.5579 - val_mae: 21.5579\n",
      "Epoch 27/200\n",
      "154/154 [==============================] - 0s 799us/step - loss: 46.2080 - mae: 46.2080 - val_loss: 21.1535 - val_mae: 21.1535\n",
      "Epoch 28/200\n",
      "154/154 [==============================] - 0s 764us/step - loss: 45.9315 - mae: 45.9315 - val_loss: 22.4650 - val_mae: 22.4650\n",
      "Epoch 29/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 46.0330 - mae: 46.0330 - val_loss: 18.9238 - val_mae: 18.9238\n",
      "Epoch 30/200\n",
      "154/154 [==============================] - 0s 760us/step - loss: 44.4770 - mae: 44.4770 - val_loss: 18.2230 - val_mae: 18.2230\n",
      "Epoch 31/200\n",
      "154/154 [==============================] - 0s 760us/step - loss: 44.7387 - mae: 44.7387 - val_loss: 18.5857 - val_mae: 18.5857\n",
      "Epoch 32/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 45.0770 - mae: 45.0770 - val_loss: 17.6359 - val_mae: 17.6359\n",
      "Epoch 33/200\n",
      "154/154 [==============================] - 0s 758us/step - loss: 44.6403 - mae: 44.6403 - val_loss: 22.5980 - val_mae: 22.5980\n",
      "Epoch 34/200\n",
      "154/154 [==============================] - 0s 760us/step - loss: 44.2168 - mae: 44.2168 - val_loss: 16.7532 - val_mae: 16.7532\n",
      "Epoch 35/200\n",
      "154/154 [==============================] - 0s 759us/step - loss: 42.8598 - mae: 42.8598 - val_loss: 17.7138 - val_mae: 17.7138\n",
      "Epoch 36/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 43.9233 - mae: 43.9233 - val_loss: 23.8483 - val_mae: 23.8483\n",
      "Epoch 37/200\n",
      "154/154 [==============================] - 0s 774us/step - loss: 42.7076 - mae: 42.7076 - val_loss: 16.3768 - val_mae: 16.3768\n",
      "Epoch 38/200\n",
      "154/154 [==============================] - 0s 755us/step - loss: 44.2584 - mae: 44.2584 - val_loss: 16.5439 - val_mae: 16.5439\n",
      "Epoch 39/200\n",
      "154/154 [==============================] - 0s 988us/step - loss: 42.8060 - mae: 42.8060 - val_loss: 14.0344 - val_mae: 14.0344\n",
      "Epoch 40/200\n",
      "154/154 [==============================] - 0s 754us/step - loss: 43.7195 - mae: 43.7195 - val_loss: 15.9063 - val_mae: 15.9063\n",
      "Epoch 41/200\n",
      "154/154 [==============================] - 0s 761us/step - loss: 43.0865 - mae: 43.0865 - val_loss: 34.4725 - val_mae: 34.4725\n",
      "Epoch 42/200\n",
      "154/154 [==============================] - 0s 765us/step - loss: 41.8142 - mae: 41.8142 - val_loss: 12.6156 - val_mae: 12.6156\n",
      "Epoch 43/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 42.4174 - mae: 42.4174 - val_loss: 12.8748 - val_mae: 12.8748\n",
      "Epoch 44/200\n",
      "154/154 [==============================] - 0s 759us/step - loss: 43.1024 - mae: 43.1024 - val_loss: 13.7153 - val_mae: 13.7153\n",
      "Epoch 45/200\n",
      "154/154 [==============================] - 0s 768us/step - loss: 42.1913 - mae: 42.1913 - val_loss: 13.1090 - val_mae: 13.1090\n",
      "Epoch 46/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 42.8541 - mae: 42.8541 - val_loss: 17.1456 - val_mae: 17.1456\n",
      "Epoch 47/200\n",
      "154/154 [==============================] - 0s 760us/step - loss: 41.7370 - mae: 41.7370 - val_loss: 15.6570 - val_mae: 15.6570\n",
      "Epoch 48/200\n",
      "154/154 [==============================] - 0s 765us/step - loss: 40.9010 - mae: 40.9010 - val_loss: 24.3376 - val_mae: 24.3376\n",
      "Epoch 49/200\n",
      "154/154 [==============================] - 0s 767us/step - loss: 41.9418 - mae: 41.9418 - val_loss: 14.3445 - val_mae: 14.3445\n",
      "Epoch 50/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 42.5319 - mae: 42.5319 - val_loss: 10.3537 - val_mae: 10.3537\n",
      "Epoch 51/200\n",
      "154/154 [==============================] - 0s 803us/step - loss: 41.5526 - mae: 41.5526 - val_loss: 12.0802 - val_mae: 12.0802\n",
      "Epoch 52/200\n",
      "154/154 [==============================] - 0s 800us/step - loss: 40.8797 - mae: 40.8797 - val_loss: 25.0251 - val_mae: 25.0251\n",
      "Epoch 53/200\n",
      "154/154 [==============================] - 0s 825us/step - loss: 41.3199 - mae: 41.3199 - val_loss: 19.8712 - val_mae: 19.8712\n",
      "Epoch 54/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 41.4522 - mae: 41.4522 - val_loss: 17.8758 - val_mae: 17.8758\n",
      "Epoch 55/200\n",
      "154/154 [==============================] - 0s 830us/step - loss: 42.4588 - mae: 42.4588 - val_loss: 25.0775 - val_mae: 25.0775\n",
      "Epoch 56/200\n",
      "154/154 [==============================] - 0s 833us/step - loss: 42.7237 - mae: 42.7237 - val_loss: 12.4734 - val_mae: 12.4734\n",
      "Epoch 57/200\n",
      "154/154 [==============================] - 0s 811us/step - loss: 43.4021 - mae: 43.4021 - val_loss: 13.0419 - val_mae: 13.0419\n",
      "Epoch 58/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 41.3983 - mae: 41.3983 - val_loss: 10.9643 - val_mae: 10.9643\n",
      "Epoch 59/200\n",
      "154/154 [==============================] - 0s 792us/step - loss: 40.0338 - mae: 40.0338 - val_loss: 29.7986 - val_mae: 29.7986\n",
      "Epoch 60/200\n",
      "154/154 [==============================] - 0s 759us/step - loss: 41.1302 - mae: 41.1302 - val_loss: 14.0798 - val_mae: 14.0798\n",
      "Epoch 61/200\n",
      "154/154 [==============================] - 0s 930us/step - loss: 40.9705 - mae: 40.9705 - val_loss: 11.2284 - val_mae: 11.2284\n",
      "Epoch 62/200\n",
      "154/154 [==============================] - 0s 755us/step - loss: 40.6138 - mae: 40.6138 - val_loss: 12.9277 - val_mae: 12.9277\n",
      "Epoch 63/200\n",
      "154/154 [==============================] - 0s 754us/step - loss: 40.5712 - mae: 40.5712 - val_loss: 23.5517 - val_mae: 23.5517\n",
      "Epoch 64/200\n",
      "154/154 [==============================] - 0s 749us/step - loss: 41.5935 - mae: 41.5935 - val_loss: 18.8093 - val_mae: 18.8093\n",
      "Epoch 65/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 42.6134 - mae: 42.6134 - val_loss: 13.5688 - val_mae: 13.5688\n",
      "Epoch 66/200\n",
      "154/154 [==============================] - 0s 747us/step - loss: 40.5857 - mae: 40.5857 - val_loss: 13.8042 - val_mae: 13.8042\n",
      "Epoch 67/200\n",
      "154/154 [==============================] - 0s 758us/step - loss: 40.6826 - mae: 40.6826 - val_loss: 22.1917 - val_mae: 22.1917\n",
      "Epoch 68/200\n",
      "154/154 [==============================] - 0s 755us/step - loss: 41.2895 - mae: 41.2895 - val_loss: 32.8675 - val_mae: 32.8675\n",
      "Epoch 69/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 42.3113 - mae: 42.3113 - val_loss: 12.9246 - val_mae: 12.9246\n",
      "Epoch 70/200\n",
      "154/154 [==============================] - 0s 769us/step - loss: 41.2084 - mae: 41.2084 - val_loss: 11.5147 - val_mae: 11.5147\n",
      "Epoch 71/200\n",
      "154/154 [==============================] - 0s 758us/step - loss: 41.2397 - mae: 41.2397 - val_loss: 20.9690 - val_mae: 20.9690\n",
      "Epoch 72/200\n",
      "154/154 [==============================] - 0s 930us/step - loss: 41.7198 - mae: 41.7198 - val_loss: 12.5967 - val_mae: 12.5967\n",
      "Epoch 73/200\n",
      "154/154 [==============================] - 0s 762us/step - loss: 43.4467 - mae: 43.4467 - val_loss: 16.8989 - val_mae: 16.8989\n",
      "Epoch 74/200\n",
      "154/154 [==============================] - 0s 760us/step - loss: 41.5106 - mae: 41.5106 - val_loss: 15.0386 - val_mae: 15.0386\n",
      "Epoch 75/200\n",
      "154/154 [==============================] - 0s 756us/step - loss: 40.2950 - mae: 40.2950 - val_loss: 10.7270 - val_mae: 10.7270\n",
      "Epoch 76/200\n",
      "154/154 [==============================] - 0s 949us/step - loss: 40.9581 - mae: 40.9581 - val_loss: 11.9439 - val_mae: 11.9439\n",
      "Epoch 77/200\n",
      "154/154 [==============================] - 0s 760us/step - loss: 40.9559 - mae: 40.9559 - val_loss: 15.5290 - val_mae: 15.5290\n",
      "Epoch 78/200\n",
      "154/154 [==============================] - 0s 755us/step - loss: 42.1994 - mae: 42.1994 - val_loss: 10.4065 - val_mae: 10.4065\n",
      "Epoch 79/200\n",
      "154/154 [==============================] - 0s 759us/step - loss: 42.1322 - mae: 42.1322 - val_loss: 10.4570 - val_mae: 10.4570\n",
      "Epoch 80/200\n",
      "154/154 [==============================] - 0s 925us/step - loss: 38.4280 - mae: 38.4280 - val_loss: 9.6144 - val_mae: 9.6144\n",
      "Epoch 81/200\n",
      "154/154 [==============================] - 0s 765us/step - loss: 41.1037 - mae: 41.1037 - val_loss: 13.2666 - val_mae: 13.2666\n",
      "Epoch 82/200\n",
      "154/154 [==============================] - 0s 775us/step - loss: 39.3525 - mae: 39.3525 - val_loss: 15.5120 - val_mae: 15.5120\n",
      "Epoch 83/200\n",
      "154/154 [==============================] - 0s 780us/step - loss: 41.1599 - mae: 41.1599 - val_loss: 11.0478 - val_mae: 11.0478\n",
      "Epoch 84/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 39.4012 - mae: 39.4012 - val_loss: 18.6269 - val_mae: 18.6269\n",
      "Epoch 85/200\n",
      "154/154 [==============================] - 0s 757us/step - loss: 38.6655 - mae: 38.6655 - val_loss: 9.5650 - val_mae: 9.5650\n",
      "Epoch 86/200\n",
      "154/154 [==============================] - 0s 765us/step - loss: 41.7443 - mae: 41.7443 - val_loss: 8.9653 - val_mae: 8.9653\n",
      "Epoch 87/200\n",
      "154/154 [==============================] - 0s 784us/step - loss: 40.8261 - mae: 40.8261 - val_loss: 7.4546 - val_mae: 7.4546\n",
      "Epoch 88/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 40.8968 - mae: 40.8968 - val_loss: 16.0821 - val_mae: 16.0821\n",
      "Epoch 89/200\n",
      "154/154 [==============================] - 0s 984us/step - loss: 41.0300 - mae: 41.0300 - val_loss: 9.8282 - val_mae: 9.8282\n",
      "Epoch 90/200\n",
      "154/154 [==============================] - 0s 800us/step - loss: 39.2236 - mae: 39.2236 - val_loss: 9.6836 - val_mae: 9.6836\n",
      "Epoch 91/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 39.8629 - mae: 39.8629 - val_loss: 12.0214 - val_mae: 12.0214\n",
      "Epoch 92/200\n",
      "154/154 [==============================] - 0s 759us/step - loss: 41.2013 - mae: 41.2013 - val_loss: 11.4426 - val_mae: 11.4426\n",
      "Epoch 93/200\n",
      "154/154 [==============================] - 0s 767us/step - loss: 42.0861 - mae: 42.0861 - val_loss: 16.7417 - val_mae: 16.7417\n",
      "Epoch 94/200\n",
      "154/154 [==============================] - 0s 954us/step - loss: 40.6736 - mae: 40.6736 - val_loss: 18.2130 - val_mae: 18.2130\n",
      "Epoch 95/200\n",
      "154/154 [==============================] - 0s 752us/step - loss: 40.1175 - mae: 40.1175 - val_loss: 9.1393 - val_mae: 9.1393\n",
      "Epoch 96/200\n",
      "154/154 [==============================] - 0s 759us/step - loss: 41.3231 - mae: 41.3231 - val_loss: 9.9650 - val_mae: 9.9650\n",
      "Epoch 97/200\n",
      "154/154 [==============================] - 0s 760us/step - loss: 43.0042 - mae: 43.0042 - val_loss: 9.1676 - val_mae: 9.1676\n",
      "Epoch 98/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 40.0309 - mae: 40.0309 - val_loss: 10.3753 - val_mae: 10.3753\n",
      "Epoch 99/200\n",
      "154/154 [==============================] - 0s 758us/step - loss: 40.2126 - mae: 40.2126 - val_loss: 10.2431 - val_mae: 10.2431\n",
      "Epoch 100/200\n",
      "154/154 [==============================] - 0s 759us/step - loss: 40.2213 - mae: 40.2213 - val_loss: 9.8029 - val_mae: 9.8029\n",
      "Epoch 101/200\n",
      "154/154 [==============================] - 0s 761us/step - loss: 39.6669 - mae: 39.6669 - val_loss: 14.7609 - val_mae: 14.7609\n",
      "Epoch 102/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 40.3775 - mae: 40.3775 - val_loss: 17.1824 - val_mae: 17.1824\n",
      "Epoch 103/200\n",
      "154/154 [==============================] - 0s 762us/step - loss: 39.5316 - mae: 39.5316 - val_loss: 10.2561 - val_mae: 10.2561\n",
      "Epoch 104/200\n",
      "154/154 [==============================] - 0s 752us/step - loss: 40.6391 - mae: 40.6391 - val_loss: 9.2007 - val_mae: 9.2007\n",
      "Epoch 105/200\n",
      "154/154 [==============================] - 0s 945us/step - loss: 41.0909 - mae: 41.0909 - val_loss: 8.1622 - val_mae: 8.1622\n",
      "Epoch 106/200\n",
      "154/154 [==============================] - 0s 758us/step - loss: 40.6741 - mae: 40.6741 - val_loss: 18.1018 - val_mae: 18.1018\n",
      "Epoch 107/200\n",
      "154/154 [==============================] - 0s 762us/step - loss: 41.7398 - mae: 41.7398 - val_loss: 10.2810 - val_mae: 10.2810\n",
      "Epoch 108/200\n",
      "154/154 [==============================] - 0s 756us/step - loss: 40.7346 - mae: 40.7346 - val_loss: 21.3192 - val_mae: 21.3192\n",
      "Epoch 109/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 39.0519 - mae: 39.0519 - val_loss: 8.7374 - val_mae: 8.7374\n",
      "Epoch 110/200\n",
      "154/154 [==============================] - 0s 774us/step - loss: 39.3745 - mae: 39.3745 - val_loss: 13.3445 - val_mae: 13.3445\n",
      "Epoch 111/200\n",
      "154/154 [==============================] - 0s 772us/step - loss: 39.6120 - mae: 39.6120 - val_loss: 9.5620 - val_mae: 9.5620\n",
      "Epoch 112/200\n",
      "154/154 [==============================] - 0s 756us/step - loss: 38.2058 - mae: 38.2058 - val_loss: 10.3955 - val_mae: 10.3955\n",
      "Epoch 113/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 39.7491 - mae: 39.7491 - val_loss: 7.5090 - val_mae: 7.5090\n",
      "Epoch 114/200\n",
      "154/154 [==============================] - 0s 782us/step - loss: 40.1582 - mae: 40.1582 - val_loss: 10.7524 - val_mae: 10.7524\n",
      "Epoch 115/200\n",
      "154/154 [==============================] - 0s 759us/step - loss: 40.0487 - mae: 40.0487 - val_loss: 6.9669 - val_mae: 6.9669\n",
      "Epoch 116/200\n",
      "154/154 [==============================] - 0s 972us/step - loss: 39.7097 - mae: 39.7097 - val_loss: 7.4400 - val_mae: 7.4400\n",
      "Epoch 117/200\n",
      "154/154 [==============================] - 0s 788us/step - loss: 39.9775 - mae: 39.9775 - val_loss: 9.3337 - val_mae: 9.3337\n",
      "Epoch 118/200\n",
      "154/154 [==============================] - 0s 802us/step - loss: 38.7422 - mae: 38.7422 - val_loss: 21.7151 - val_mae: 21.7151\n",
      "Epoch 119/200\n",
      "154/154 [==============================] - 0s 794us/step - loss: 39.5385 - mae: 39.5385 - val_loss: 11.0942 - val_mae: 11.0942\n",
      "Epoch 120/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 38.4603 - mae: 38.4603 - val_loss: 13.3109 - val_mae: 13.3109\n",
      "Epoch 121/200\n",
      "154/154 [==============================] - 0s 774us/step - loss: 40.8018 - mae: 40.8018 - val_loss: 10.5764 - val_mae: 10.5764\n",
      "Epoch 122/200\n",
      "154/154 [==============================] - 0s 781us/step - loss: 39.4796 - mae: 39.4796 - val_loss: 14.5608 - val_mae: 14.5608\n",
      "Epoch 123/200\n",
      "154/154 [==============================] - 0s 789us/step - loss: 41.1207 - mae: 41.1207 - val_loss: 9.8618 - val_mae: 9.8618\n",
      "Epoch 124/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 38.2903 - mae: 38.2903 - val_loss: 10.4405 - val_mae: 10.4405\n",
      "Epoch 125/200\n",
      "154/154 [==============================] - 0s 771us/step - loss: 40.2816 - mae: 40.2816 - val_loss: 7.9299 - val_mae: 7.9299\n",
      "Epoch 126/200\n",
      "154/154 [==============================] - 0s 761us/step - loss: 39.2091 - mae: 39.2091 - val_loss: 7.8038 - val_mae: 7.8038\n",
      "Epoch 127/200\n",
      "154/154 [==============================] - 0s 977us/step - loss: 39.2374 - mae: 39.2374 - val_loss: 9.3696 - val_mae: 9.3696\n",
      "Epoch 128/200\n",
      "154/154 [==============================] - 0s 782us/step - loss: 38.6457 - mae: 38.6457 - val_loss: 7.4137 - val_mae: 7.4137\n",
      "Epoch 129/200\n",
      "154/154 [==============================] - 0s 821us/step - loss: 40.2595 - mae: 40.2595 - val_loss: 9.2659 - val_mae: 9.2659\n",
      "Epoch 130/200\n",
      "154/154 [==============================] - 0s 763us/step - loss: 38.9493 - mae: 38.9493 - val_loss: 8.2729 - val_mae: 8.2729\n",
      "Epoch 131/200\n",
      "154/154 [==============================] - 0s 768us/step - loss: 39.3538 - mae: 39.3538 - val_loss: 8.4903 - val_mae: 8.4903\n",
      "Epoch 132/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 38.8924 - mae: 38.8924 - val_loss: 12.7974 - val_mae: 12.7974\n",
      "Epoch 133/200\n",
      "154/154 [==============================] - 0s 798us/step - loss: 38.3420 - mae: 38.3420 - val_loss: 12.7133 - val_mae: 12.7133\n",
      "Epoch 134/200\n",
      "154/154 [==============================] - 0s 834us/step - loss: 40.0374 - mae: 40.0374 - val_loss: 10.7425 - val_mae: 10.7425\n",
      "Epoch 135/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 40.8990 - mae: 40.8990 - val_loss: 16.6487 - val_mae: 16.6487\n",
      "Epoch 136/200\n",
      "154/154 [==============================] - 0s 752us/step - loss: 39.9271 - mae: 39.9271 - val_loss: 13.8588 - val_mae: 13.8588\n",
      "Epoch 137/200\n",
      "154/154 [==============================] - 0s 764us/step - loss: 39.3644 - mae: 39.3644 - val_loss: 15.4604 - val_mae: 15.4604\n",
      "Epoch 138/200\n",
      "154/154 [==============================] - 0s 985us/step - loss: 39.6239 - mae: 39.6239 - val_loss: 17.6776 - val_mae: 17.6776\n",
      "Epoch 139/200\n",
      "154/154 [==============================] - 0s 753us/step - loss: 39.9453 - mae: 39.9453 - val_loss: 8.5795 - val_mae: 8.5795\n",
      "Epoch 140/200\n",
      "154/154 [==============================] - 0s 763us/step - loss: 39.9876 - mae: 39.9876 - val_loss: 16.5979 - val_mae: 16.5979\n",
      "Epoch 141/200\n",
      "154/154 [==============================] - 0s 761us/step - loss: 40.6161 - mae: 40.6161 - val_loss: 23.6525 - val_mae: 23.6525\n",
      "Epoch 142/200\n",
      "154/154 [==============================] - 0s 857us/step - loss: 38.7752 - mae: 38.7752 - val_loss: 7.7785 - val_mae: 7.7785\n",
      "Epoch 143/200\n",
      "154/154 [==============================] - 0s 765us/step - loss: 39.5274 - mae: 39.5274 - val_loss: 13.8702 - val_mae: 13.8702\n",
      "Epoch 144/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 38.5606 - mae: 38.5606 - val_loss: 5.3027 - val_mae: 5.3027\n",
      "Epoch 145/200\n",
      "154/154 [==============================] - 0s 750us/step - loss: 39.3747 - mae: 39.3747 - val_loss: 16.0928 - val_mae: 16.0928\n",
      "Epoch 146/200\n",
      "154/154 [==============================] - 0s 762us/step - loss: 37.8743 - mae: 37.8743 - val_loss: 7.9022 - val_mae: 7.9022\n",
      "Epoch 147/200\n",
      "154/154 [==============================] - 0s 965us/step - loss: 40.1540 - mae: 40.1540 - val_loss: 8.8790 - val_mae: 8.8790\n",
      "Epoch 148/200\n",
      "154/154 [==============================] - 0s 763us/step - loss: 38.8151 - mae: 38.8151 - val_loss: 16.3426 - val_mae: 16.3426\n",
      "Epoch 149/200\n",
      "154/154 [==============================] - 0s 806us/step - loss: 39.2821 - mae: 39.2821 - val_loss: 6.6758 - val_mae: 6.6758\n",
      "Epoch 150/200\n",
      "154/154 [==============================] - 0s 773us/step - loss: 41.6326 - mae: 41.6326 - val_loss: 7.4085 - val_mae: 7.4085\n",
      "Epoch 151/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 40.2006 - mae: 40.2006 - val_loss: 8.2047 - val_mae: 8.2047\n",
      "Epoch 152/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 36.4193 - mae: 36.4193 - val_loss: 7.3408 - val_mae: 7.3408\n",
      "Epoch 153/200\n",
      "154/154 [==============================] - 0s 926us/step - loss: 37.2706 - mae: 37.2706 - val_loss: 12.6028 - val_mae: 12.6028\n",
      "Epoch 154/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 38.2886 - mae: 38.2886 - val_loss: 6.2460 - val_mae: 6.2460\n",
      "Epoch 155/200\n",
      "154/154 [==============================] - 0s 788us/step - loss: 38.3232 - mae: 38.3232 - val_loss: 10.8980 - val_mae: 10.8980\n",
      "Epoch 156/200\n",
      "154/154 [==============================] - 0s 758us/step - loss: 41.0471 - mae: 41.0471 - val_loss: 15.4127 - val_mae: 15.4127\n",
      "Epoch 157/200\n",
      "154/154 [==============================] - 0s 961us/step - loss: 37.5976 - mae: 37.5976 - val_loss: 7.7780 - val_mae: 7.7780\n",
      "Epoch 158/200\n",
      "154/154 [==============================] - 0s 771us/step - loss: 39.9911 - mae: 39.9911 - val_loss: 8.5327 - val_mae: 8.5327\n",
      "Epoch 159/200\n",
      "154/154 [==============================] - 0s 773us/step - loss: 39.1613 - mae: 39.1613 - val_loss: 24.4211 - val_mae: 24.4211\n",
      "Epoch 160/200\n",
      "154/154 [==============================] - 0s 804us/step - loss: 37.8106 - mae: 37.8106 - val_loss: 12.3675 - val_mae: 12.3675\n",
      "Epoch 161/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 37.0828 - mae: 37.0828 - val_loss: 11.0925 - val_mae: 11.0925\n",
      "Epoch 162/200\n",
      "154/154 [==============================] - 0s 834us/step - loss: 39.5242 - mae: 39.5242 - val_loss: 12.1201 - val_mae: 12.1201\n",
      "Epoch 163/200\n",
      "154/154 [==============================] - 0s 767us/step - loss: 39.0428 - mae: 39.0428 - val_loss: 13.5951 - val_mae: 13.5951\n",
      "Epoch 164/200\n",
      "154/154 [==============================] - 0s 801us/step - loss: 39.0386 - mae: 39.0386 - val_loss: 16.0320 - val_mae: 16.0320\n",
      "Epoch 165/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 40.1372 - mae: 40.1372 - val_loss: 7.1878 - val_mae: 7.1878\n",
      "Epoch 166/200\n",
      "154/154 [==============================] - 0s 939us/step - loss: 38.4396 - mae: 38.4396 - val_loss: 13.2600 - val_mae: 13.2600\n",
      "Epoch 167/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 36.7274 - mae: 36.7274 - val_loss: 10.1919 - val_mae: 10.1919\n",
      "Epoch 168/200\n",
      "154/154 [==============================] - 0s 763us/step - loss: 37.3292 - mae: 37.3292 - val_loss: 12.2898 - val_mae: 12.2898\n",
      "Epoch 169/200\n",
      "154/154 [==============================] - 0s 764us/step - loss: 40.2632 - mae: 40.2632 - val_loss: 7.3933 - val_mae: 7.3933\n",
      "Epoch 170/200\n",
      "154/154 [==============================] - 0s 760us/step - loss: 38.1170 - mae: 38.1170 - val_loss: 12.6245 - val_mae: 12.6245\n",
      "Epoch 171/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 39.9905 - mae: 39.9905 - val_loss: 6.9728 - val_mae: 6.9728\n",
      "Epoch 172/200\n",
      "154/154 [==============================] - 0s 783us/step - loss: 37.3604 - mae: 37.3604 - val_loss: 13.0518 - val_mae: 13.0518\n",
      "Epoch 173/200\n",
      "154/154 [==============================] - 0s 869us/step - loss: 37.8830 - mae: 37.8830 - val_loss: 11.9046 - val_mae: 11.9046\n",
      "Epoch 174/200\n",
      "154/154 [==============================] - 0s 847us/step - loss: 39.7542 - mae: 39.7542 - val_loss: 7.1201 - val_mae: 7.1201\n",
      "Epoch 175/200\n",
      "154/154 [==============================] - 0s 849us/step - loss: 40.2259 - mae: 40.2259 - val_loss: 6.3644 - val_mae: 6.3644\n",
      "Epoch 176/200\n",
      "154/154 [==============================] - 0s 764us/step - loss: 39.1461 - mae: 39.1461 - val_loss: 9.8447 - val_mae: 9.8447\n",
      "Epoch 177/200\n",
      "154/154 [==============================] - 0s 855us/step - loss: 38.1600 - mae: 38.1600 - val_loss: 7.2432 - val_mae: 7.2432\n",
      "Epoch 178/200\n",
      "154/154 [==============================] - 0s 857us/step - loss: 41.3482 - mae: 41.3482 - val_loss: 7.0219 - val_mae: 7.0219\n",
      "Epoch 179/200\n",
      "154/154 [==============================] - 0s 850us/step - loss: 38.0702 - mae: 38.0702 - val_loss: 8.1542 - val_mae: 8.1542\n",
      "Epoch 180/200\n",
      "154/154 [==============================] - 0s 839us/step - loss: 39.7879 - mae: 39.7879 - val_loss: 6.2061 - val_mae: 6.2061\n",
      "Epoch 181/200\n",
      "154/154 [==============================] - 0s 777us/step - loss: 40.1234 - mae: 40.1234 - val_loss: 6.5514 - val_mae: 6.5514\n",
      "Epoch 182/200\n",
      "154/154 [==============================] - 0s 755us/step - loss: 40.2281 - mae: 40.2281 - val_loss: 8.7629 - val_mae: 8.7629\n",
      "Epoch 183/200\n",
      "154/154 [==============================] - 0s 759us/step - loss: 38.6021 - mae: 38.6021 - val_loss: 6.2444 - val_mae: 6.2444\n",
      "Epoch 184/200\n",
      "154/154 [==============================] - 0s 756us/step - loss: 37.9579 - mae: 37.9579 - val_loss: 8.6002 - val_mae: 8.6002\n",
      "Epoch 185/200\n",
      "154/154 [==============================] - 0s 757us/step - loss: 38.2172 - mae: 38.2172 - val_loss: 7.6008 - val_mae: 7.6008\n",
      "Epoch 186/200\n",
      "154/154 [==============================] - 0s 890us/step - loss: 39.1081 - mae: 39.1081 - val_loss: 7.8238 - val_mae: 7.8238\n",
      "Epoch 187/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 40.3582 - mae: 40.3582 - val_loss: 7.9312 - val_mae: 7.9312\n",
      "Epoch 188/200\n",
      "154/154 [==============================] - 0s 760us/step - loss: 38.3899 - mae: 38.3899 - val_loss: 10.2227 - val_mae: 10.2227\n",
      "Epoch 189/200\n",
      "154/154 [==============================] - 0s 754us/step - loss: 38.7540 - mae: 38.7540 - val_loss: 22.8421 - val_mae: 22.8421\n",
      "Epoch 190/200\n",
      "154/154 [==============================] - 0s 911us/step - loss: 39.1330 - mae: 39.1330 - val_loss: 9.5987 - val_mae: 9.5987\n",
      "Epoch 191/200\n",
      "154/154 [==============================] - 0s 760us/step - loss: 38.8910 - mae: 38.8910 - val_loss: 6.3094 - val_mae: 6.3094\n",
      "Epoch 192/200\n",
      "154/154 [==============================] - 0s 785us/step - loss: 39.4332 - mae: 39.4332 - val_loss: 20.5223 - val_mae: 20.5223\n",
      "Epoch 193/200\n",
      "154/154 [==============================] - 0s 754us/step - loss: 39.9517 - mae: 39.9517 - val_loss: 16.1765 - val_mae: 16.1765\n",
      "Epoch 194/200\n",
      "154/154 [==============================] - 0s 927us/step - loss: 37.6685 - mae: 37.6685 - val_loss: 8.1732 - val_mae: 8.1732\n",
      "Epoch 195/200\n",
      "154/154 [==============================] - 0s 760us/step - loss: 40.1459 - mae: 40.1459 - val_loss: 6.6762 - val_mae: 6.6762\n",
      "Epoch 196/200\n",
      "154/154 [==============================] - 0s 791us/step - loss: 39.7315 - mae: 39.7315 - val_loss: 6.5907 - val_mae: 6.5907\n",
      "Epoch 197/200\n",
      "154/154 [==============================] - 0s 783us/step - loss: 37.2179 - mae: 37.2179 - val_loss: 5.2240 - val_mae: 5.2240\n",
      "Epoch 198/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 39.8863 - mae: 39.8863 - val_loss: 8.4338 - val_mae: 8.4338\n",
      "Epoch 199/200\n",
      "154/154 [==============================] - 0s 783us/step - loss: 37.8261 - mae: 37.8261 - val_loss: 6.2361 - val_mae: 6.2361\n",
      "Epoch 200/200\n",
      "154/154 [==============================] - 0s 781us/step - loss: 38.5827 - mae: 38.5827 - val_loss: 7.5824 - val_mae: 7.5824\n",
      "Epoch 1/200\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 650.9316 - mae: 650.9316 - val_loss: 343.0288 - val_mae: 343.0288\n",
      "Epoch 2/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 291.9405 - mae: 291.9405 - val_loss: 219.0050 - val_mae: 219.0050\n",
      "Epoch 3/200\n",
      "154/154 [==============================] - 0s 827us/step - loss: 188.3589 - mae: 188.3589 - val_loss: 133.6485 - val_mae: 133.6485\n",
      "Epoch 4/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 119.8836 - mae: 119.8836 - val_loss: 87.6219 - val_mae: 87.6219\n",
      "Epoch 5/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 99.9164 - mae: 99.9164 - val_loss: 71.7712 - val_mae: 71.7712\n",
      "Epoch 6/200\n",
      "154/154 [==============================] - 0s 757us/step - loss: 84.4761 - mae: 84.4761 - val_loss: 60.7536 - val_mae: 60.7536\n",
      "Epoch 7/200\n",
      "154/154 [==============================] - 0s 778us/step - loss: 80.2637 - mae: 80.2637 - val_loss: 55.3317 - val_mae: 55.3317\n",
      "Epoch 8/200\n",
      "154/154 [==============================] - 0s 754us/step - loss: 76.5099 - mae: 76.5099 - val_loss: 49.0854 - val_mae: 49.0854\n",
      "Epoch 9/200\n",
      "154/154 [==============================] - 0s 762us/step - loss: 71.5633 - mae: 71.5633 - val_loss: 47.4097 - val_mae: 47.4097\n",
      "Epoch 10/200\n",
      "154/154 [==============================] - 0s 759us/step - loss: 63.2678 - mae: 63.2678 - val_loss: 42.4557 - val_mae: 42.4557\n",
      "Epoch 11/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 64.3445 - mae: 64.3445 - val_loss: 41.1836 - val_mae: 41.1836\n",
      "Epoch 12/200\n",
      "154/154 [==============================] - 0s 762us/step - loss: 60.2710 - mae: 60.2710 - val_loss: 37.8237 - val_mae: 37.8237\n",
      "Epoch 13/200\n",
      "154/154 [==============================] - 0s 760us/step - loss: 60.3452 - mae: 60.3452 - val_loss: 34.7511 - val_mae: 34.7511\n",
      "Epoch 14/200\n",
      "154/154 [==============================] - 0s 756us/step - loss: 58.5336 - mae: 58.5336 - val_loss: 35.8881 - val_mae: 35.8881\n",
      "Epoch 15/200\n",
      "154/154 [==============================] - 0s 764us/step - loss: 57.1468 - mae: 57.1468 - val_loss: 29.9992 - val_mae: 29.9992\n",
      "Epoch 16/200\n",
      "154/154 [==============================] - 0s 757us/step - loss: 56.6801 - mae: 56.6801 - val_loss: 41.0592 - val_mae: 41.0592\n",
      "Epoch 17/200\n",
      "154/154 [==============================] - 0s 797us/step - loss: 55.3140 - mae: 55.3140 - val_loss: 32.2890 - val_mae: 32.2890\n",
      "Epoch 18/200\n",
      "154/154 [==============================] - 0s 763us/step - loss: 54.4195 - mae: 54.4195 - val_loss: 25.6997 - val_mae: 25.6997\n",
      "Epoch 19/200\n",
      "154/154 [==============================] - 0s 762us/step - loss: 50.4465 - mae: 50.4465 - val_loss: 24.9464 - val_mae: 24.9464\n",
      "Epoch 20/200\n",
      "154/154 [==============================] - 0s 761us/step - loss: 52.1293 - mae: 52.1293 - val_loss: 39.3577 - val_mae: 39.3577\n",
      "Epoch 21/200\n",
      "154/154 [==============================] - 0s 759us/step - loss: 50.4839 - mae: 50.4839 - val_loss: 19.6836 - val_mae: 19.6836\n",
      "Epoch 22/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 48.6987 - mae: 48.6987 - val_loss: 18.8895 - val_mae: 18.8895\n",
      "Epoch 23/200\n",
      "154/154 [==============================] - 0s 779us/step - loss: 47.6620 - mae: 47.6620 - val_loss: 25.4043 - val_mae: 25.4043\n",
      "Epoch 24/200\n",
      "154/154 [==============================] - 0s 782us/step - loss: 49.1899 - mae: 49.1899 - val_loss: 20.1234 - val_mae: 20.1234\n",
      "Epoch 25/200\n",
      "154/154 [==============================] - 0s 754us/step - loss: 46.5183 - mae: 46.5183 - val_loss: 17.4607 - val_mae: 17.4607\n",
      "Epoch 26/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 49.5506 - mae: 49.5506 - val_loss: 27.5234 - val_mae: 27.5234\n",
      "Epoch 27/200\n",
      "154/154 [==============================] - 0s 761us/step - loss: 43.9532 - mae: 43.9532 - val_loss: 21.5839 - val_mae: 21.5839\n",
      "Epoch 28/200\n",
      "154/154 [==============================] - 0s 792us/step - loss: 46.9743 - mae: 46.9743 - val_loss: 23.3826 - val_mae: 23.3826\n",
      "Epoch 29/200\n",
      "154/154 [==============================] - 0s 932us/step - loss: 44.7581 - mae: 44.7581 - val_loss: 34.5235 - val_mae: 34.5235\n",
      "Epoch 30/200\n",
      "154/154 [==============================] - 0s 764us/step - loss: 43.7868 - mae: 43.7868 - val_loss: 18.1322 - val_mae: 18.1322\n",
      "Epoch 31/200\n",
      "154/154 [==============================] - 0s 775us/step - loss: 43.6008 - mae: 43.6008 - val_loss: 14.1045 - val_mae: 14.1045\n",
      "Epoch 32/200\n",
      "154/154 [==============================] - 0s 762us/step - loss: 43.9934 - mae: 43.9934 - val_loss: 27.0934 - val_mae: 27.0934\n",
      "Epoch 33/200\n",
      "154/154 [==============================] - 0s 943us/step - loss: 43.3854 - mae: 43.3854 - val_loss: 25.5085 - val_mae: 25.5085\n",
      "Epoch 34/200\n",
      "154/154 [==============================] - 0s 762us/step - loss: 44.2024 - mae: 44.2024 - val_loss: 33.5711 - val_mae: 33.5711\n",
      "Epoch 35/200\n",
      "154/154 [==============================] - 0s 764us/step - loss: 42.1939 - mae: 42.1939 - val_loss: 31.4183 - val_mae: 31.4183\n",
      "Epoch 36/200\n",
      "154/154 [==============================] - 0s 770us/step - loss: 43.1909 - mae: 43.1909 - val_loss: 15.3502 - val_mae: 15.3502\n",
      "Epoch 37/200\n",
      "154/154 [==============================] - 0s 931us/step - loss: 41.9457 - mae: 41.9457 - val_loss: 13.9919 - val_mae: 13.9919\n",
      "Epoch 38/200\n",
      "154/154 [==============================] - 0s 768us/step - loss: 43.5877 - mae: 43.5877 - val_loss: 25.3377 - val_mae: 25.3377\n",
      "Epoch 39/200\n",
      "154/154 [==============================] - 0s 808us/step - loss: 44.7338 - mae: 44.7338 - val_loss: 10.0462 - val_mae: 10.0462\n",
      "Epoch 40/200\n",
      "154/154 [==============================] - 0s 951us/step - loss: 42.9721 - mae: 42.9721 - val_loss: 17.4114 - val_mae: 17.4114\n",
      "Epoch 41/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 43.2239 - mae: 43.2239 - val_loss: 31.1167 - val_mae: 31.1167\n",
      "Epoch 42/200\n",
      "154/154 [==============================] - 0s 920us/step - loss: 40.7933 - mae: 40.7933 - val_loss: 17.4118 - val_mae: 17.4118\n",
      "Epoch 43/200\n",
      "154/154 [==============================] - 0s 752us/step - loss: 43.8882 - mae: 43.8882 - val_loss: 32.3875 - val_mae: 32.3875\n",
      "Epoch 44/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 43.6952 - mae: 43.6952 - val_loss: 22.5681 - val_mae: 22.5681\n",
      "Epoch 45/200\n",
      "154/154 [==============================] - 0s 776us/step - loss: 40.4327 - mae: 40.4327 - val_loss: 9.1057 - val_mae: 9.1057\n",
      "Epoch 46/200\n",
      "154/154 [==============================] - 0s 762us/step - loss: 42.1517 - mae: 42.1517 - val_loss: 13.5230 - val_mae: 13.5230\n",
      "Epoch 47/200\n",
      "154/154 [==============================] - 0s 936us/step - loss: 42.3706 - mae: 42.3706 - val_loss: 27.1892 - val_mae: 27.1892\n",
      "Epoch 48/200\n",
      "154/154 [==============================] - 0s 777us/step - loss: 40.0368 - mae: 40.0368 - val_loss: 11.5259 - val_mae: 11.5259\n",
      "Epoch 49/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 42.4825 - mae: 42.4825 - val_loss: 26.3213 - val_mae: 26.3213\n",
      "Epoch 50/200\n",
      "154/154 [==============================] - 0s 755us/step - loss: 44.5131 - mae: 44.5131 - val_loss: 8.9404 - val_mae: 8.9404\n",
      "Epoch 51/200\n",
      "154/154 [==============================] - 0s 762us/step - loss: 42.7712 - mae: 42.7712 - val_loss: 16.3453 - val_mae: 16.3453\n",
      "Epoch 52/200\n",
      "154/154 [==============================] - 0s 761us/step - loss: 42.5809 - mae: 42.5809 - val_loss: 11.2245 - val_mae: 11.2245\n",
      "Epoch 53/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 40.2814 - mae: 40.2814 - val_loss: 17.0250 - val_mae: 17.0250\n",
      "Epoch 54/200\n",
      "154/154 [==============================] - 0s 757us/step - loss: 40.6104 - mae: 40.6104 - val_loss: 27.7954 - val_mae: 27.7954\n",
      "Epoch 55/200\n",
      "154/154 [==============================] - 0s 757us/step - loss: 41.3887 - mae: 41.3887 - val_loss: 10.6171 - val_mae: 10.6171\n",
      "Epoch 56/200\n",
      "154/154 [==============================] - 0s 951us/step - loss: 40.7525 - mae: 40.7525 - val_loss: 25.1344 - val_mae: 25.1344\n",
      "Epoch 57/200\n",
      "154/154 [==============================] - 0s 767us/step - loss: 41.0863 - mae: 41.0863 - val_loss: 19.8001 - val_mae: 19.8001\n",
      "Epoch 58/200\n",
      "154/154 [==============================] - 0s 998us/step - loss: 42.4597 - mae: 42.4597 - val_loss: 10.3279 - val_mae: 10.3279\n",
      "Epoch 59/200\n",
      "154/154 [==============================] - 0s 800us/step - loss: 41.7008 - mae: 41.7008 - val_loss: 10.7867 - val_mae: 10.7867\n",
      "Epoch 60/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 43.3229 - mae: 43.3229 - val_loss: 12.8101 - val_mae: 12.8101\n",
      "Epoch 61/200\n",
      "154/154 [==============================] - 0s 772us/step - loss: 41.8728 - mae: 41.8728 - val_loss: 17.8898 - val_mae: 17.8898\n",
      "Epoch 62/200\n",
      "154/154 [==============================] - 0s 792us/step - loss: 41.3610 - mae: 41.3610 - val_loss: 16.2585 - val_mae: 16.2585\n",
      "Epoch 63/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 41.7646 - mae: 41.7646 - val_loss: 14.6186 - val_mae: 14.6186\n",
      "Epoch 64/200\n",
      "154/154 [==============================] - 0s 756us/step - loss: 42.4578 - mae: 42.4578 - val_loss: 25.5990 - val_mae: 25.5990\n",
      "Epoch 65/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 43.3703 - mae: 43.3703 - val_loss: 8.9185 - val_mae: 8.9185\n",
      "Epoch 66/200\n",
      "154/154 [==============================] - 0s 772us/step - loss: 42.5084 - mae: 42.5084 - val_loss: 25.9531 - val_mae: 25.9531\n",
      "Epoch 67/200\n",
      "154/154 [==============================] - 0s 754us/step - loss: 41.0244 - mae: 41.0244 - val_loss: 12.5394 - val_mae: 12.5394\n",
      "Epoch 68/200\n",
      "154/154 [==============================] - 0s 983us/step - loss: 42.6201 - mae: 42.6201 - val_loss: 22.8673 - val_mae: 22.8673\n",
      "Epoch 69/200\n",
      "154/154 [==============================] - 0s 794us/step - loss: 40.8706 - mae: 40.8706 - val_loss: 9.1287 - val_mae: 9.1287\n",
      "Epoch 70/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 41.7186 - mae: 41.7186 - val_loss: 13.8310 - val_mae: 13.8310\n",
      "Epoch 71/200\n",
      "154/154 [==============================] - 0s 771us/step - loss: 41.4528 - mae: 41.4528 - val_loss: 22.4569 - val_mae: 22.4569\n",
      "Epoch 72/200\n",
      "154/154 [==============================] - 0s 762us/step - loss: 42.4236 - mae: 42.4236 - val_loss: 16.9550 - val_mae: 16.9550\n",
      "Epoch 73/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 41.4804 - mae: 41.4804 - val_loss: 8.5605 - val_mae: 8.5605\n",
      "Epoch 74/200\n",
      "154/154 [==============================] - 0s 770us/step - loss: 41.1335 - mae: 41.1335 - val_loss: 21.7587 - val_mae: 21.7587\n",
      "Epoch 75/200\n",
      "154/154 [==============================] - 0s 761us/step - loss: 41.6066 - mae: 41.6066 - val_loss: 8.4027 - val_mae: 8.4027\n",
      "Epoch 76/200\n",
      "154/154 [==============================] - 0s 762us/step - loss: 41.4627 - mae: 41.4627 - val_loss: 11.5740 - val_mae: 11.5740\n",
      "Epoch 77/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 41.7698 - mae: 41.7698 - val_loss: 18.5710 - val_mae: 18.5710\n",
      "Epoch 78/200\n",
      "154/154 [==============================] - 0s 764us/step - loss: 40.5704 - mae: 40.5704 - val_loss: 8.7024 - val_mae: 8.7024\n",
      "Epoch 79/200\n",
      "154/154 [==============================] - 0s 798us/step - loss: 41.3572 - mae: 41.3572 - val_loss: 8.1026 - val_mae: 8.1026\n",
      "Epoch 80/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 41.3293 - mae: 41.3293 - val_loss: 17.5969 - val_mae: 17.5969\n",
      "Epoch 81/200\n",
      "154/154 [==============================] - 0s 810us/step - loss: 41.5202 - mae: 41.5202 - val_loss: 22.0732 - val_mae: 22.0732\n",
      "Epoch 82/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 42.9843 - mae: 42.9843 - val_loss: 15.3421 - val_mae: 15.3421\n",
      "Epoch 83/200\n",
      "154/154 [==============================] - 0s 778us/step - loss: 42.0823 - mae: 42.0823 - val_loss: 5.9032 - val_mae: 5.9032\n",
      "Epoch 84/200\n",
      "154/154 [==============================] - 0s 768us/step - loss: 42.4536 - mae: 42.4536 - val_loss: 19.4285 - val_mae: 19.4285\n",
      "Epoch 85/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 42.8570 - mae: 42.8570 - val_loss: 12.2174 - val_mae: 12.2174\n",
      "Epoch 86/200\n",
      "154/154 [==============================] - 0s 764us/step - loss: 43.1272 - mae: 43.1272 - val_loss: 7.8240 - val_mae: 7.8240\n",
      "Epoch 87/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 41.3196 - mae: 41.3196 - val_loss: 7.4449 - val_mae: 7.4449\n",
      "Epoch 88/200\n",
      "154/154 [==============================] - 0s 846us/step - loss: 40.5288 - mae: 40.5288 - val_loss: 9.8007 - val_mae: 9.8007\n",
      "Epoch 89/200\n",
      "154/154 [==============================] - 0s 782us/step - loss: 40.6932 - mae: 40.6932 - val_loss: 9.1890 - val_mae: 9.1890\n",
      "Epoch 90/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 41.4780 - mae: 41.4780 - val_loss: 8.6497 - val_mae: 8.6497\n",
      "Epoch 91/200\n",
      "154/154 [==============================] - 0s 758us/step - loss: 43.0933 - mae: 43.0933 - val_loss: 14.0605 - val_mae: 14.0605\n",
      "Epoch 92/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 42.6659 - mae: 42.6659 - val_loss: 12.3685 - val_mae: 12.3685\n",
      "Epoch 93/200\n",
      "154/154 [==============================] - 0s 779us/step - loss: 40.1776 - mae: 40.1776 - val_loss: 7.4266 - val_mae: 7.4266\n",
      "Epoch 94/200\n",
      "154/154 [==============================] - 0s 783us/step - loss: 41.1245 - mae: 41.1245 - val_loss: 21.3462 - val_mae: 21.3462\n",
      "Epoch 95/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 43.1403 - mae: 43.1403 - val_loss: 8.0885 - val_mae: 8.0885\n",
      "Epoch 96/200\n",
      "154/154 [==============================] - 0s 797us/step - loss: 41.2139 - mae: 41.2139 - val_loss: 19.2300 - val_mae: 19.2300\n",
      "Epoch 97/200\n",
      "154/154 [==============================] - 0s 828us/step - loss: 40.8593 - mae: 40.8593 - val_loss: 6.8308 - val_mae: 6.8308\n",
      "Epoch 98/200\n",
      "154/154 [==============================] - 0s 782us/step - loss: 40.6743 - mae: 40.6743 - val_loss: 14.5852 - val_mae: 14.5852\n",
      "Epoch 99/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 40.0166 - mae: 40.0166 - val_loss: 22.4745 - val_mae: 22.4745\n",
      "Epoch 100/200\n",
      "154/154 [==============================] - 0s 780us/step - loss: 42.2598 - mae: 42.2598 - val_loss: 13.0985 - val_mae: 13.0985\n",
      "Epoch 101/200\n",
      "154/154 [==============================] - 0s 775us/step - loss: 39.7037 - mae: 39.7037 - val_loss: 23.4868 - val_mae: 23.4868\n",
      "Epoch 102/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 39.8308 - mae: 39.8308 - val_loss: 8.6672 - val_mae: 8.6672\n",
      "Epoch 103/200\n",
      "154/154 [==============================] - 0s 772us/step - loss: 42.1363 - mae: 42.1363 - val_loss: 19.2946 - val_mae: 19.2946\n",
      "Epoch 104/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 41.4651 - mae: 41.4651 - val_loss: 15.2775 - val_mae: 15.2775\n",
      "Epoch 105/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 41.2195 - mae: 41.2195 - val_loss: 7.3488 - val_mae: 7.3488\n",
      "Epoch 106/200\n",
      "154/154 [==============================] - 0s 807us/step - loss: 40.7267 - mae: 40.7267 - val_loss: 9.4562 - val_mae: 9.4562\n",
      "Epoch 107/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 41.8125 - mae: 41.8125 - val_loss: 5.4102 - val_mae: 5.4102\n",
      "Epoch 108/200\n",
      "154/154 [==============================] - 0s 785us/step - loss: 42.3356 - mae: 42.3356 - val_loss: 12.8206 - val_mae: 12.8206\n",
      "Epoch 109/200\n",
      "154/154 [==============================] - 0s 765us/step - loss: 42.1374 - mae: 42.1374 - val_loss: 27.0649 - val_mae: 27.0649\n",
      "Epoch 110/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 39.7698 - mae: 39.7698 - val_loss: 8.4569 - val_mae: 8.4569\n",
      "Epoch 111/200\n",
      "154/154 [==============================] - 0s 768us/step - loss: 43.5726 - mae: 43.5726 - val_loss: 22.6204 - val_mae: 22.6204\n",
      "Epoch 112/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 40.2220 - mae: 40.2220 - val_loss: 22.9431 - val_mae: 22.9431\n",
      "Epoch 113/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 40.6315 - mae: 40.6315 - val_loss: 18.7099 - val_mae: 18.7099\n",
      "Epoch 114/200\n",
      "154/154 [==============================] - 0s 762us/step - loss: 41.2240 - mae: 41.2240 - val_loss: 18.1197 - val_mae: 18.1197\n",
      "Epoch 115/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 40.7000 - mae: 40.7000 - val_loss: 19.5304 - val_mae: 19.5304\n",
      "Epoch 116/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 40.2961 - mae: 40.2961 - val_loss: 7.7367 - val_mae: 7.7367\n",
      "Epoch 117/200\n",
      "154/154 [==============================] - 0s 767us/step - loss: 41.2488 - mae: 41.2488 - val_loss: 6.8467 - val_mae: 6.8467\n",
      "Epoch 118/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 42.2854 - mae: 42.2854 - val_loss: 18.2115 - val_mae: 18.2115\n",
      "Epoch 119/200\n",
      "154/154 [==============================] - 0s 756us/step - loss: 41.5925 - mae: 41.5925 - val_loss: 8.0079 - val_mae: 8.0079\n",
      "Epoch 120/200\n",
      "154/154 [==============================] - 0s 758us/step - loss: 38.6021 - mae: 38.6021 - val_loss: 19.4619 - val_mae: 19.4619\n",
      "Epoch 121/200\n",
      "154/154 [==============================] - 0s 997us/step - loss: 41.9454 - mae: 41.9454 - val_loss: 20.7440 - val_mae: 20.7440\n",
      "Epoch 122/200\n",
      "154/154 [==============================] - 0s 762us/step - loss: 40.9174 - mae: 40.9174 - val_loss: 19.4453 - val_mae: 19.4453\n",
      "Epoch 123/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 40.5958 - mae: 40.5958 - val_loss: 29.6694 - val_mae: 29.6694\n",
      "Epoch 124/200\n",
      "154/154 [==============================] - 0s 991us/step - loss: 42.3308 - mae: 42.3308 - val_loss: 13.4957 - val_mae: 13.4957\n",
      "Epoch 125/200\n",
      "154/154 [==============================] - 0s 767us/step - loss: 42.2926 - mae: 42.2926 - val_loss: 6.0450 - val_mae: 6.0450\n",
      "Epoch 126/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 41.9615 - mae: 41.9615 - val_loss: 14.4330 - val_mae: 14.4330\n",
      "Epoch 127/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 39.7560 - mae: 39.7560 - val_loss: 6.9282 - val_mae: 6.9282\n",
      "Epoch 128/200\n",
      "154/154 [==============================] - 0s 809us/step - loss: 41.6619 - mae: 41.6619 - val_loss: 16.6992 - val_mae: 16.6992\n",
      "Epoch 129/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 40.5997 - mae: 40.5997 - val_loss: 11.3185 - val_mae: 11.3185\n",
      "Epoch 130/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 43.0384 - mae: 43.0384 - val_loss: 12.5691 - val_mae: 12.5691\n",
      "Epoch 131/200\n",
      "154/154 [==============================] - 0s 763us/step - loss: 40.6764 - mae: 40.6764 - val_loss: 12.4667 - val_mae: 12.4667\n",
      "Epoch 132/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 39.7058 - mae: 39.7058 - val_loss: 7.7306 - val_mae: 7.7306\n",
      "Epoch 133/200\n",
      "154/154 [==============================] - 0s 929us/step - loss: 43.6938 - mae: 43.6938 - val_loss: 6.6039 - val_mae: 6.6039\n",
      "Epoch 134/200\n",
      "154/154 [==============================] - 0s 762us/step - loss: 41.1482 - mae: 41.1482 - val_loss: 16.5906 - val_mae: 16.5906\n",
      "Epoch 135/200\n",
      "154/154 [==============================] - 0s 975us/step - loss: 42.2540 - mae: 42.2540 - val_loss: 12.0546 - val_mae: 12.0546\n",
      "Epoch 136/200\n",
      "154/154 [==============================] - 0s 801us/step - loss: 40.5080 - mae: 40.5080 - val_loss: 21.4794 - val_mae: 21.4794\n",
      "Epoch 137/200\n",
      "154/154 [==============================] - 0s 933us/step - loss: 41.3971 - mae: 41.3971 - val_loss: 14.1769 - val_mae: 14.1769\n",
      "Epoch 138/200\n",
      "154/154 [==============================] - 0s 827us/step - loss: 40.4805 - mae: 40.4805 - val_loss: 13.2796 - val_mae: 13.2796\n",
      "Epoch 139/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 41.4481 - mae: 41.4481 - val_loss: 20.1690 - val_mae: 20.1690\n",
      "Epoch 140/200\n",
      "154/154 [==============================] - 0s 835us/step - loss: 40.1284 - mae: 40.1284 - val_loss: 17.6072 - val_mae: 17.6072\n",
      "Epoch 141/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 42.8487 - mae: 42.8487 - val_loss: 8.7023 - val_mae: 8.7023\n",
      "Epoch 142/200\n",
      "154/154 [==============================] - 0s 920us/step - loss: 40.4212 - mae: 40.4212 - val_loss: 9.6120 - val_mae: 9.6120\n",
      "Epoch 143/200\n",
      "154/154 [==============================] - 0s 807us/step - loss: 40.7704 - mae: 40.7704 - val_loss: 12.3188 - val_mae: 12.3188\n",
      "Epoch 144/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 42.0273 - mae: 42.0273 - val_loss: 8.6527 - val_mae: 8.6527\n",
      "Epoch 145/200\n",
      "154/154 [==============================] - 0s 850us/step - loss: 39.6734 - mae: 39.6734 - val_loss: 6.4240 - val_mae: 6.4240\n",
      "Epoch 146/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 42.4961 - mae: 42.4961 - val_loss: 22.5157 - val_mae: 22.5157\n",
      "Epoch 147/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 41.9506 - mae: 41.9506 - val_loss: 12.4992 - val_mae: 12.4992\n",
      "Epoch 148/200\n",
      "154/154 [==============================] - 0s 787us/step - loss: 41.8784 - mae: 41.8784 - val_loss: 20.6326 - val_mae: 20.6326\n",
      "Epoch 149/200\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 41.0480 - mae: 41.0480 - val_loss: 15.8533 - val_mae: 15.8533\n",
      "Epoch 150/200\n",
      "154/154 [==============================] - 0s 925us/step - loss: 41.2083 - mae: 41.2083 - val_loss: 10.0937 - val_mae: 10.0937\n",
      "Epoch 151/200\n",
      "154/154 [==============================] - 0s 791us/step - loss: 44.2337 - mae: 44.2337 - val_loss: 31.3566 - val_mae: 31.3566\n",
      "Epoch 152/200\n",
      "145/154 [===========================>..] - ETA: 0s - loss: 42.0126 - mae: 42.0126"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/Cam/Documents/FinTech-MSc/INAI/Intro-to-AI/Coursework/BIKES-Q1 copy.ipynb Cell 37'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Cam/Documents/FinTech-MSc/INAI/Intro-to-AI/Coursework/BIKES-Q1%20copy.ipynb#ch0000037?line=0'>1</a>\u001b[0m start_time \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mnow()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/Cam/Documents/FinTech-MSc/INAI/Intro-to-AI/Coursework/BIKES-Q1%20copy.ipynb#ch0000037?line=2'>3</a>\u001b[0m tuner_rs\u001b[39m.\u001b[39;49msearch(X_train1, y_train1, epochs\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(X_val, y_val)) \u001b[39m#, verbose=0)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Cam/Documents/FinTech-MSc/INAI/Intro-to-AI/Coursework/BIKES-Q1%20copy.ipynb#ch0000037?line=4'>5</a>\u001b[0m end_time \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mnow()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Cam/Documents/FinTech-MSc/INAI/Intro-to-AI/Coursework/BIKES-Q1%20copy.ipynb#ch0000037?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mDuration: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(end_time \u001b[39m-\u001b[39m start_time))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras_tuner/engine/base_tuner.py:179\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/keras_tuner/engine/base_tuner.py?line=175'>176</a>\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/keras_tuner/engine/base_tuner.py?line=177'>178</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/keras_tuner/engine/base_tuner.py?line=178'>179</a>\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[1;32m    <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/keras_tuner/engine/base_tuner.py?line=179'>180</a>\u001b[0m \u001b[39m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/keras_tuner/engine/base_tuner.py?line=180'>181</a>\u001b[0m \u001b[39mif\u001b[39;00m results \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras_tuner/engine/tuner.py:304\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/keras_tuner/engine/tuner.py?line=301'>302</a>\u001b[0m callbacks\u001b[39m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/keras_tuner/engine/tuner.py?line=302'>303</a>\u001b[0m copied_kwargs[\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m callbacks\n\u001b[0;32m--> <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/keras_tuner/engine/tuner.py?line=303'>304</a>\u001b[0m obj_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_and_fit_model(trial, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcopied_kwargs)\n\u001b[1;32m    <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/keras_tuner/engine/tuner.py?line=305'>306</a>\u001b[0m \u001b[39m# objective left unspecified,\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/keras_tuner/engine/tuner.py?line=306'>307</a>\u001b[0m \u001b[39m# and objective value is not a single float.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/keras_tuner/engine/tuner.py?line=307'>308</a>\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/keras_tuner/engine/tuner.py?line=308'>309</a>\u001b[0m     \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(obj_value, (\u001b[39mint\u001b[39m, \u001b[39mfloat\u001b[39m))\n\u001b[1;32m    <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/keras_tuner/engine/tuner.py?line=309'>310</a>\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mobjective\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdefault_objective\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/keras_tuner/engine/tuner.py?line=310'>311</a>\u001b[0m ):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras_tuner/engine/tuner.py:234\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/keras_tuner/engine/tuner.py?line=231'>232</a>\u001b[0m hp \u001b[39m=\u001b[39m trial\u001b[39m.\u001b[39mhyperparameters\n\u001b[1;32m    <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/keras_tuner/engine/tuner.py?line=232'>233</a>\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/keras_tuner/engine/tuner.py?line=233'>234</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhypermodel\u001b[39m.\u001b[39;49mfit(hp, model, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras_tuner/engine/hypermodel.py:137\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/keras_tuner/engine/hypermodel.py?line=112'>113</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, hp, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/keras_tuner/engine/hypermodel.py?line=113'>114</a>\u001b[0m     \u001b[39m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/keras_tuner/engine/hypermodel.py?line=114'>115</a>\u001b[0m \n\u001b[1;32m    <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/keras_tuner/engine/hypermodel.py?line=115'>116</a>\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/keras_tuner/engine/hypermodel.py?line=134'>135</a>\u001b[0m \u001b[39m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/keras_tuner/engine/hypermodel.py?line=135'>136</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/keras_tuner/engine/hypermodel.py?line=136'>137</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39;49mfit(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1131\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1116'>1117</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_frame \u001b[39m=\u001b[39m tf_inspect\u001b[39m.\u001b[39mcurrentframe()\n\u001b[1;32m   <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1117'>1118</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39mDataHandler(\n\u001b[1;32m   <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1118'>1119</a>\u001b[0m       x\u001b[39m=\u001b[39mval_x,\n\u001b[1;32m   <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1119'>1120</a>\u001b[0m       y\u001b[39m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1128'>1129</a>\u001b[0m       model\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m,\n\u001b[1;32m   <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1129'>1130</a>\u001b[0m       steps_per_execution\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution)\n\u001b[0;32m-> <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1130'>1131</a>\u001b[0m val_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(\n\u001b[1;32m   <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1131'>1132</a>\u001b[0m     x\u001b[39m=\u001b[39;49mval_x,\n\u001b[1;32m   <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1132'>1133</a>\u001b[0m     y\u001b[39m=\u001b[39;49mval_y,\n\u001b[1;32m   <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1133'>1134</a>\u001b[0m     sample_weight\u001b[39m=\u001b[39;49mval_sample_weight,\n\u001b[1;32m   <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1134'>1135</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49mvalidation_batch_size \u001b[39mor\u001b[39;49;00m batch_size,\n\u001b[1;32m   <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1135'>1136</a>\u001b[0m     steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[1;32m   <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1136'>1137</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1137'>1138</a>\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1138'>1139</a>\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1139'>1140</a>\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1140'>1141</a>\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m   <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1141'>1142</a>\u001b[0m val_logs \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m name: val \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m val_logs\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m   <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1142'>1143</a>\u001b[0m epoch_logs\u001b[39m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1349\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1343'>1344</a>\u001b[0m _disallow_inside_tf_function(\u001b[39m'\u001b[39m\u001b[39mevaluate\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1345'>1346</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy\u001b[39m.\u001b[39mscope():\n\u001b[1;32m   <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1346'>1347</a>\u001b[0m   \u001b[39m# Use cached evaluation data only when it's called in `Model.fit`\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1347'>1348</a>\u001b[0m   \u001b[39mif\u001b[39;00m (\u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_fit_frame\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1348'>1349</a>\u001b[0m       \u001b[39mand\u001b[39;00m tf_inspect\u001b[39m.\u001b[39;49mcurrentframe()\u001b[39m.\u001b[39mf_back \u001b[39mis\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_frame\n\u001b[1;32m   <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1349'>1350</a>\u001b[0m       \u001b[39mand\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_eval_data_handler\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1350'>1351</a>\u001b[0m     data_handler \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_data_handler\n\u001b[1;32m   <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1351'>1352</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1352'>1353</a>\u001b[0m     \u001b[39m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_inspect.py:95\u001b[0m, in \u001b[0;36mcurrentframe\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_inspect.py?line=92'>93</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcurrentframe\u001b[39m():\n\u001b[1;32m     <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_inspect.py?line=93'>94</a>\u001b[0m   \u001b[39m\"\"\"TFDecorator-aware replacement for inspect.currentframe.\"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_inspect.py?line=94'>95</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m _inspect\u001b[39m.\u001b[39;49mstack()[\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/inspect.py:1526\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(context)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/inspect.py?line=1523'>1524</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstack\u001b[39m(context\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/inspect.py?line=1524'>1525</a>\u001b[0m     \u001b[39m\"\"\"Return a list of records for the stack above the caller's frame.\"\"\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/inspect.py?line=1525'>1526</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m getouterframes(sys\u001b[39m.\u001b[39;49m_getframe(\u001b[39m1\u001b[39;49m), context)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/inspect.py:1503\u001b[0m, in \u001b[0;36mgetouterframes\u001b[0;34m(frame, context)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/inspect.py?line=1500'>1501</a>\u001b[0m framelist \u001b[39m=\u001b[39m []\n\u001b[1;32m   <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/inspect.py?line=1501'>1502</a>\u001b[0m \u001b[39mwhile\u001b[39;00m frame:\n\u001b[0;32m-> <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/inspect.py?line=1502'>1503</a>\u001b[0m     frameinfo \u001b[39m=\u001b[39m (frame,) \u001b[39m+\u001b[39m getframeinfo(frame, context)\n\u001b[1;32m   <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/inspect.py?line=1503'>1504</a>\u001b[0m     framelist\u001b[39m.\u001b[39mappend(FrameInfo(\u001b[39m*\u001b[39mframeinfo))\n\u001b[1;32m   <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/inspect.py?line=1504'>1505</a>\u001b[0m     frame \u001b[39m=\u001b[39m frame\u001b[39m.\u001b[39mf_back\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/inspect.py:1473\u001b[0m, in \u001b[0;36mgetframeinfo\u001b[0;34m(frame, context)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/inspect.py?line=1469'>1470</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m isframe(frame):\n\u001b[1;32m   <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/inspect.py?line=1470'>1471</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m is not a frame or traceback object\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(frame))\n\u001b[0;32m-> <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/inspect.py?line=1472'>1473</a>\u001b[0m filename \u001b[39m=\u001b[39m getsourcefile(frame) \u001b[39mor\u001b[39;00m getfile(frame)\n\u001b[1;32m   <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/inspect.py?line=1473'>1474</a>\u001b[0m \u001b[39mif\u001b[39;00m context \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/inspect.py?line=1474'>1475</a>\u001b[0m     start \u001b[39m=\u001b[39m lineno \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m context\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/inspect.py:708\u001b[0m, in \u001b[0;36mgetsourcefile\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/inspect.py?line=705'>706</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m filename\n\u001b[1;32m    <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/inspect.py?line=706'>707</a>\u001b[0m \u001b[39m# only return a non-existent filename if the module has a PEP 302 loader\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/inspect.py?line=707'>708</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(getmodule(\u001b[39mobject\u001b[39;49m, filename), \u001b[39m'\u001b[39m\u001b[39m__loader__\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/inspect.py?line=708'>709</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m filename\n\u001b[1;32m    <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/inspect.py?line=709'>710</a>\u001b[0m \u001b[39m# or it is in the linecache\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/inspect.py:744\u001b[0m, in \u001b[0;36mgetmodule\u001b[0;34m(object, _filename)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/inspect.py?line=740'>741</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m sys\u001b[39m.\u001b[39mmodules\u001b[39m.\u001b[39mget(modulesbyfile[file])\n\u001b[1;32m    <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/inspect.py?line=741'>742</a>\u001b[0m \u001b[39m# Update the filename to module name cache and check yet again\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/inspect.py?line=742'>743</a>\u001b[0m \u001b[39m# Copy sys.modules in order to cope with changes while iterating\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/inspect.py?line=743'>744</a>\u001b[0m \u001b[39mfor\u001b[39;00m modname, module \u001b[39min\u001b[39;00m sys\u001b[39m.\u001b[39mmodules\u001b[39m.\u001b[39mcopy()\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/inspect.py?line=744'>745</a>\u001b[0m     \u001b[39mif\u001b[39;00m ismodule(module) \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(module, \u001b[39m'\u001b[39m\u001b[39m__file__\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    <a href='file:///Users/Cam/opt/anaconda3/lib/python3.8/inspect.py?line=745'>746</a>\u001b[0m         f \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39m\u001b[39m__file__\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "tuner_rs.search(X_train1, y_train1, epochs=200, validation_data=(X_val, y_val)) #, verbose=0)\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect best hyperparameters to rebuild model\n",
    "best_model = tuner_rs.get_best_hyperparameters()[0]\n",
    "model = tuner_rs.hypermodel.build(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the Model\n",
    "history = model.fit(X_train1, y_train1, batch_size = 10, epochs = 100, validation_data=(X_val, y_val), verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss\n",
    "plt.plot(history.history['loss'])\n",
    "#plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Loss', 'Validation Loss'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get new predicted values with Hyperparameters\n",
    "y_best_model_pred = model.predict(X_test)\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot predicted values against test values\n",
    "plt.plot(y_test, color = 'red', label = 'Real data')\n",
    "plt.plot(y_best_model_pred, color = 'blue', label = 'HP Predicted data')\n",
    "plt.title('HP Prediction')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the output metrics\n",
    "from sklearn import metrics\n",
    "\n",
    "y_hp_pred=y_best_model_pred\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_hp_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_hp_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_hp_pred)))\n",
    "\n",
    "y_mean = np.mean(y_hp_pred)\n",
    "y_std = np.std(y_hp_pred)\n",
    "print('Output Standard Deviation:', y_std)\n",
    "print('Output Mean:', y_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_rs.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model performance\n",
    "### Using the Close value as the Adjusted Close value for that day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/Cam/Documents/FinTech-MSc/INAI/Intro-to-AI/Coursework/BIKES-Q1.ipynb Cell 29'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Cam/Documents/FinTech-MSc/INAI/Intro-to-AI/Coursework/BIKES-Q1.ipynb#ch0000014?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m mean_squared_error, mean_absolute_error\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Cam/Documents/FinTech-MSc/INAI/Intro-to-AI/Coursework/BIKES-Q1.ipynb#ch0000014?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmath\u001b[39;00m \u001b[39mimport\u001b[39;00m sqrt\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/Cam/Documents/FinTech-MSc/INAI/Intro-to-AI/Coursework/BIKES-Q1.ipynb#ch0000014?line=5'>6</a>\u001b[0m Close_test \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(X_test[\u001b[39m'\u001b[39;49m\u001b[39mClose\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Cam/Documents/FinTech-MSc/INAI/Intro-to-AI/Coursework/BIKES-Q1.ipynb#ch0000014?line=6'>7</a>\u001b[0m BL_r2 \u001b[39m=\u001b[39m r2_score(y_test, Close_test)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Cam/Documents/FinTech-MSc/INAI/Intro-to-AI/Coursework/BIKES-Q1.ipynb#ch0000014?line=7'>8</a>\u001b[0m BL_RMSE \u001b[39m=\u001b[39m sqrt(mean_squared_error(y_test, Close_test))\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "Close_test = pd.DataFrame(X_test['Close'])\n",
    "BL_r2 = r2_score(y_test, Close_test)\n",
    "BL_RMSE = sqrt(mean_squared_error(y_test, Close_test))\n",
    "BL_MAE = sqrt(mean_absolute_error(y_test, Close_test))\n",
    "\n",
    "print('BASELINE MODEL:')\n",
    "print('Using the Close value of that day as the Adjusted Close value prediction')\n",
    "print('    - The R^2 score on test dataset = ',BL_r2)\n",
    "print('    - RMSE on test dataset = ', BL_RMSE)\n",
    "print('    - MAE on test dataset = ', BL_MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search for best parameters for Ridge model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', Ridge(max_iter=100000, tol=0.001))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GridSearchCV(pipeline,\n",
    "                     {'model__alpha':np.linspace(0.002,0.005,20)},\n",
    "                     cv=4,\n",
    "                     scoring = 'neg_root_mean_squared_error',\n",
    "                     verbose=0\n",
    "                     \n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4,\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('model', Ridge(max_iter=100000))]),\n",
       "             param_grid={'model__alpha': array([0.002     , 0.00215789, 0.00231579, 0.00247368, 0.00263158,\n",
       "       0.00278947, 0.00294737, 0.00310526, 0.00326316, 0.00342105,\n",
       "       0.00357895, 0.00373684, 0.00389474, 0.00405263, 0.00421053,\n",
       "       0.00436842, 0.00452632, 0.00468421, 0.00484211, 0.005     ])},\n",
       "             scoring='neg_root_mean_squared_error')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__alpha': 0.005}\n",
      "[-2.41085064e-03 -3.42805697e-02 -6.24916655e-01 -3.06145130e+00\n",
      "  2.77992432e+00  1.82008146e+00  1.21381841e+01]\n",
      "Features included in the Lasso model: ['Day' 'Month' 'Year' 'Open' 'High' 'Low' 'Close']\n",
      "Features discarded from the Lasso model: []\n"
     ]
    }
   ],
   "source": [
    "print(search.best_params_)\n",
    "coef = search.best_estimator_[1].coef_\n",
    "print(coef)\n",
    "print(\"Features included in the Lasso model:\", np.array(features)[coef != 0])\n",
    "print(\"Features discarded from the Lasso model:\", np.array(features)[coef == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression model:\n",
      "Train:\n",
      "    - R^2 score =  0.9985841413249849\n",
      "    - RMSE =  0.49478609626767367\n",
      "    - MAE =  0.6135777204118708\n",
      "Test:\n",
      "    - R^2 score =  0.9939710622884429\n",
      "    - RMSE =  2.929886023563268\n",
      "    - MAE =  1.664706878225074\n"
     ]
    }
   ],
   "source": [
    "pred_train = search.best_estimator_.predict(X_train)\n",
    "pred_test = search.best_estimator_.predict(X_test)\n",
    "\n",
    "print('Ridge Regression model:')\n",
    "print(\"Train:\")\n",
    "print('    - R^2 score = ',r2_score(y_true= y_train, y_pred= pred_train))\n",
    "print('    - RMSE = ', sqrt(mean_squared_error(y_true= y_train, y_pred= pred_train)))\n",
    "print('    - MAE = ', sqrt(mean_absolute_error(y_true= y_train, y_pred= pred_train)))\n",
    "print(\"Test:\")\n",
    "print('    - R^2 score = ',r2_score(y_true= y_test, y_pred= pred_test))\n",
    "print('    - RMSE = ', sqrt(mean_squared_error(y_true= y_test, y_pred= pred_test)))\n",
    "print('    - MAE = ', sqrt(mean_absolute_error(y_true= y_test, y_pred= pred_test)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fd2ba105aab07b6a173e1db60e29d63cb192fbaecb08760dc9f1bb9ec4b3c40f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
